{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Project-Document_Level",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1F_sbTbLE6o",
        "colab_type": "code",
        "outputId": "2c092974-6081-4ebc-96c4-f19231e94409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib0ylvcgMJYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import io\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJYDAhdUMQWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AJtGl6oMUlk",
        "colab_type": "code",
        "outputId": "c30a0c5f-4244-4c35-b884-7b6b613ea5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf0kgmxsMYUd",
        "colab_type": "code",
        "outputId": "50fc3045-5497-4c38-fbd1-50f9de4cd3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/PROJECT - NLP/semantic-segmentation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PROJECT - NLP/semantic-segmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMZ3dwd9M9Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Documnets = []\n",
        "with open('categories.txt','r+') as f:\n",
        "    doc = f.read()\n",
        "    for fil in doc.split('\\n'):\n",
        "      if len(fil.split('\\t')) == 2:\n",
        "        for names in fil.split('\\t')[1].split(\" \"):\n",
        "          Documnets.append(names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NKDFmRgNbfk",
        "colab_type": "code",
        "outputId": "01181486-c507-44dd-9baf-fa53ce1d7a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/PROJECT - NLP/semantic-segmentation/data/text/files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PROJECT - NLP/semantic-segmentation/data/text/files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SHwAyzINdF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_docs , test_docs = train_test_split(Documnets,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIScipwSQuV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = []\n",
        "classes = []\n",
        "\n",
        "for filename in train_docs:\n",
        "  with io.open(filename+'.txt','r') as f:\n",
        "    file = f.read()\n",
        "  for i in range(len(file.split('\\n'))):\n",
        "    if len(file.split('\\n')[i].split('\\t')) == 2:\n",
        "      s = file.split('\\n')[i].split('\\t')[0]\n",
        "      sent.append(s)\n",
        "      classes.append(file.split('\\n')[i].split('\\t')[1])\n",
        "\n",
        "dic = {'Sentence':sent,'Class':classes}\n",
        "df2 = pd.DataFrame(dic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjisr08zSoge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "enc = LabelEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ7pol35TDPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc.fit(classes)\n",
        "classes = enc.transform(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifjy2_NcTJ0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.concat([df2,pd.DataFrame(list(classes))],axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcnLlEDYTeM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.columns = ['Sentence','Class','Labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZYNPYhvThz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df2.Sentence.values\n",
        "labels = df2.Labels.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLsp1V7tTvO8",
        "colab_type": "code",
        "outputId": "5c8f6651-32db-4125-9141-d4c1fef912b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzSrHSrRT3Hd",
        "colab_type": "code",
        "outputId": "b790174a-d20d-4ea0-8148-1be531a98db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  This appeal is by special leave against the judgment and decree of the High Court of Kerala which dismissed an appeal against the judgment and decree of the Subordinate Court of Havelikkara\n",
            "Token IDs: tensor([  101,  2023,  5574,  2003,  2011,  2569,  2681,  2114,  1996,  8689,\n",
            "         1998, 10037,  1997,  1996,  2152,  2457,  1997,  8935,  2029,  7219,\n",
            "         2019,  5574,  2114,  1996,  8689,  1998, 10037,  1997,  1996, 15144,\n",
            "         2457,  1997,  2031, 18393, 16566,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXFZVm8nT57r",
        "colab_type": "code",
        "outputId": "63879419-dff8-40c0-9481-e6c9a8c9653c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6,033 training samples\n",
            "1,509 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8AeAtoBT_GG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sedE-5VIUNY2",
        "colab_type": "code",
        "outputId": "e19e18b8-b06a-435f-c5fd-c8d6427f48f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 7,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcFC4fi6UaOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrgupXIvUgGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv07iXDXUmeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQrOWx5gUo3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nrA7oD0Uqs8",
        "colab_type": "code",
        "outputId": "3ff0710a-f859-4abc-b80d-ef334736c66a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    40  of    189.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    189.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    189.    Elapsed: 0:01:17.\n",
            "  Batch   160  of    189.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 1.33\n",
            "  Training epcoh took: 0:02:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.59\n",
            "  Validation Loss: 1.20\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    189.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    189.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    189.    Elapsed: 0:01:17.\n",
            "  Batch   160  of    189.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.96\n",
            "  Training epcoh took: 0:02:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    189.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    189.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    189.    Elapsed: 0:01:17.\n",
            "  Batch   160  of    189.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epcoh took: 0:02:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 1.18\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    189.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    189.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    189.    Elapsed: 0:01:17.\n",
            "  Batch   160  of    189.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Training epcoh took: 0:02:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation Loss: 1.19\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:08:43 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_xzokbnUwZM",
        "colab_type": "code",
        "outputId": "06b2a75f-faef-4278-e68b-7369b38dde01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.330354</td>\n",
              "      <td>1.195321</td>\n",
              "      <td>0.590234</td>\n",
              "      <td>0:02:01</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.959906</td>\n",
              "      <td>1.082128</td>\n",
              "      <td>0.631250</td>\n",
              "      <td>0:02:01</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.663102</td>\n",
              "      <td>1.180799</td>\n",
              "      <td>0.623437</td>\n",
              "      <td>0:02:01</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.444505</td>\n",
              "      <td>1.193117</td>\n",
              "      <td>0.629948</td>\n",
              "      <td>0:02:01</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1           1.330354     1.195321       0.590234       0:02:01         0:00:10\n",
              "2           0.959906     1.082128       0.631250       0:02:01         0:00:10\n",
              "3           0.663102     1.180799       0.623437       0:02:01         0:00:10\n",
              "4           0.444505     1.193117       0.629948       0:02:01         0:00:10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZYZedoSU5Vl",
        "colab_type": "code",
        "outputId": "7fb8f78b-fceb-425c-8c00-66f6ca75cfed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeVxU9f4/8NesIMO+76DgICIgLuBWKibuLWJpuZSW1b1t1++tbrZe7df93rp1W7/qLb2V5RIhlZK7mGYI7rsiooDsiMoyI8vMnN8fwMgI6qDAGeD1fDx6JGfOOfNm9MO8+Mz7fI5EEAQBREREREQkGqnYBRARERERdXcM5UREREREImMoJyIiIiISGUM5EREREZHIGMqJiIiIiETGUE5EREREJDKGciLqsvLy8hASEoLPP//8js/x2muvISQkpA2r6rpu9nqHhITgtddeM+scn3/+OUJCQpCXl9fm9SUlJSEkJATp6eltfm4iorslF7sAIuo+WhNud+zYAV9f33aspvPRarVYtmwZNm7ciJKSEjg7O2PgwIH485//jKCgILPO8eKLL2LLli34+eefERoa2uI+giBgzJgxqKiowJ49e2Btbd2W30a7Sk9Px759+/D444/D3t5e7HKaycvLw5gxYzBz5ky8/fbbYpdDRBaEoZyIOswHH3xg8vXBgwfxww8/YPr06Rg4cKDJY87Oznf9fD4+Pjh27BhkMtkdn+Pdd9/FokWL7rqWtvDmm2/i119/xeTJkxEdHY3S0lKkpKTg6NGjZofyadOmYcuWLVi3bh3efPPNFvdJS0tDfn4+pk+f3iaB/NixY5BKO+aD2X379uGLL77AQw891CyUP/DAA5g0aRIUCkWH1EJE1BoM5UTUYR544AGTr/V6PX744Qf079+/2WM3qqqqgq2tbaueTyKRwMrKqtV1NmUpAe7atWvYvHkzRowYgY8++si4/fnnn0dtba3Z5xkxYgS8vLywYcMGvPrqq1Aqlc32SUpKAlAf4NvC3f4dtBWZTHZXv6AREbUn9pQTkcWJjY3F7NmzcerUKTz55JMYOHAg7r//fgD14fzjjz/Gww8/jJiYGPTr1w9jx47Fhx9+iGvXrpmcp6Ue56bbdu7cifj4eISHh2PEiBF4//33odPpTM7RUk9547bKykq88847GDp0KMLDwzFjxgwcPXq02fdz5coVLFy4EDExMYiKisKcOXNw6tQpzJ49G7GxsWa9JhKJBBKJpMVfEloK1jcjlUrx0EMP4erVq0hJSWn2eFVVFbZu3Qq1Wo2IiIhWvd4301JPucFgwH/+8x/ExsYiPDwckydPxvr161s8PisrC3//+98xadIkREVFITIyElOnTsWPP/5ost9rr72GL774AgAwZswYhISEmPz936yn/PLly1i0aBFGjhyJfv36YeTIkVi0aBGuXLlisl/j8Xv37sWKFStw3333oV+/fhg3bhx++ukns16L1jhz5gyee+45xMTEIDw8HBMnTsRXX30FvV5vsl9hYSEWLlyI0aNHo1+/fhg6dChmzJhhUpPBYMA333yDKVOmICoqCgMGDMC4cePw+uuvo66urs1rJ6LW40w5EVmkgoICPP744xg/fjzi4uKg1WoBAMXFxUhMTERcXBwmT54MuVyOffv2Yfny5Th9+jRWrFhh1vl37dqF1atXY8aMGYiPj8eOHTvw3//+Fw4ODnj22WfNOseTTz4JZ2dnPPfcc7h69Sq+/vprPP3009ixY4dxVr+2thZz587F6dOnMXXqVISHhyMjIwNz586Fg4OD2a+HtbU1HnzwQaxbtw7JycmYPHmy2cfeaOrUqVi6dCmSkpIwfvx4k8d+/fVXVFdXIz4+HkDbvd43+t///V+sXLkSgwcPxhNPPIGysjIsXrwYfn5+zfbdt28fDhw4gFGjRsHX19f4qcGbb76Jy5cv45lnngEATJ8+HVVVVdi2bRsWLlwIJycnALe+lqGyshKPPvoocnJyEB8fj759++L06dNYs2YN0tLS8OOPPzb7hObjjz9GdXU1pk+fDqVSiTVr1uC1116Dv79/szasO3X8+HHMnj0bcrkcM2fOhKurK3bu3IkPP/wQZ86cMX5aotPpMHfuXBQXF+Oxxx5DYGAgqqqqkJGRgQMHDuChhx4CACxduhSfffYZRo8ejRkzZkAmkyEvLw8pKSmora21mE+EiLo1gYhIJOvWrRPUarWwbt06k+2jR48W1Gq1kJCQ0OyYmpoaoba2ttn2jz/+WFCr1cLRo0eN2y5evCio1Wrhs88+a7YtMjJSuHjxonG7wWAQJk2aJAwfPtzkvH/7298EtVrd4rZ33nnHZPvGjRsFtVotrFmzxrjt+++/F9RqtbBkyRKTfRu3jx49utn30pLKykph/vz5Qr9+/YS+ffsKv/76q1nH3cycOXOE0NBQobi42GT7I488IoSFhQllZWWCINz96y0IgqBWq4W//e1vxq+zsrKEkJAQYc6cOYJOpzNuP3HihBASEiKo1WqTvxuNRtPs+fV6vTBr1ixhwIABJvV99tlnzY5v1PjvLS0tzbjt3//+t6BWq4Xvv//eZN/Gv5+PP/642fEPPPCAUFNTY9xeVFQkhIWFCQsWLGj2nDdqfI0WLVp0y/2mT58uhIaGCqdPnzZuMxgMwosvviio1WohNTVVEARBOH36tKBWq4Uvv/zylud78MEHhQkTJty2PiISD9tXiMgiOTo6YurUqc22K5VK46yeTqdDeXk5Ll++jGHDhgFAi+0jLRkzZozJ6i4SiQQxMTEoLS2FRqMx6xxPPPGEyddDhgwBAOTk5Bi37dy5EzKZDHPmzDHZ9+GHH4adnZ1Zz2MwGPDSSy/hzJkz2LRpE+699168/PLL2LBhg8l+b731FsLCwszqMZ82bRr0ej1+/vln47asrCwcOXIEsbGxxgtt2+r1bmrHjh0QBAFz58416fEOCwvD8OHDm+1vY2Nj/HNNTQ2uXLmCq1evYvjw4aiqqsL58+dbXUOjbdu2wdnZGdOnTzfZPn36dDg7O2P79u3NjnnsscdMWoY8PDzQs2dPZGdn33EdTZWVleHw4cOIjY1Fnz59jNslEgn+9Kc/GesGYPw3lJ6ejrKyspue09bWFsXFxThw4ECb1EhEbY/tK0Rkkfz8/G56Ud6qVauwdu1anDt3DgaDweSx8vJys89/I0dHRwDA1atXoVKpWn2OxnaJq1evGrfl5eXB3d292fmUSiV8fX1RUVFx2+fZsWMH9uzZg3/961/w9fXFp59+iueffx6vvvoqdDqdsUUhIyMD4eHhZvWYx8XFwd7eHklJSXj66acBAOvWrQMAY+tKo7Z4vZu6ePEiAKBXr17NHgsKCsKePXtMtmk0GnzxxRfYtGkTCgsLmx1jzmt4M3l5eejXrx/kctO3Q7lcjsDAQJw6darZMTf7t5Ofn3/HddxYEwAEBwc3e6xXr16QSqXG19DHxwfPPvssvvzyS4wYMQKhoaEYMmQIxo8fj4iICONx//M//4PnnnsOM2fOhLu7O6KjozFq1CiMGzeuVdckEFH7YSgnIovUo0ePFrd//fXX+Oc//4kRI0Zgzpw5cHd3h0KhQHFxMV577TUIgmDW+W+1CsfdnsPc483VeGHi4MGDAdQH+i+++AJ/+tOfsHDhQuh0OvTp0wdHjx7Fe++9Z9Y5raysMHnyZKxevRqHDh1CZGQk1q9fD09PT9xzzz3G/drq9b4bf/3rX/Hbb7/hkUceweDBg+Ho6AiZTIZdu3bhm2++afaLQnvrqOUdzbVgwQJMmzYNv/32Gw4cOIDExESsWLECTz31FF555RUAQFRUFLZt24Y9e/YgPT0d6enpSE5OxtKlS7F69WrjL6REJB6GciLqVH755Rf4+Pjgq6++MglHu3fvFrGqm/Px8cHevXuh0WhMZsvr6uqQl5dn1g1uGr/P/Px8eHl5AagP5kuWLMGzzz6Lt956Cz4+PlCr1XjwwQfNrm3atGlYvXo1kpKSUF5ejtLSUjz77LMmr2t7vN6NM83nz5+Hv7+/yWNZWVkmX1dUVOC3337DAw88gMWLF5s8lpqa2uzcEomk1bVcuHABOp3OZLZcp9MhOzu7xVnx9tbYVnXu3Llmj50/fx4Gg6FZXX5+fpg9ezZmz56NmpoaPPnkk1i+fDnmzZsHFxcXAIBKpcK4ceMwbtw4APWfgCxevBiJiYl46qmn2vm7IqLbsaxf94mIbkMqlUIikZjM0Op0Onz11VciVnVzsbGx0Ov1WLlypcn2hIQEVFZWmnWOkSNHAqhf9aNpv7iVlRX+/e9/w97eHnl5eRg3blyzNoxbCQsLQ2hoKDZu3IhVq1ZBIpE0W5u8PV7v2NhYSCQSfP311ybL+508ebJZ0G78ReDGGfmSkpJmSyIC1/vPzW2rue+++3D58uVm50pISMDly5dx3333mXWetuTi4oKoqCjs3LkTZ8+eNW4XBAFffvklAGDs2LEA6lePuXFJQysrK2NrUOPrcPny5WbPExYWZrIPEYmLM+VE1KmMHz8eH330EebPn4+xY8eiqqoKycnJrQqjHenhhx/G2rVr8cknnyA3N9e4JOLmzZsREBDQbF30lgwfPhzTpk1DYmIiJk2ahAceeACenp64ePEifvnlFwD1Aev//u//EBQUhAkTJphd37Rp0/Duu+/i999/R3R0dLMZ2PZ4vYOCgjBz5kx8//33ePzxxxEXF4eysjKsWrUKffr0MenjtrW1xfDhw7F+/XpYW1sjPDwc+fn5+OGHH+Dr62vSvw8AkZGRAIAPP/wQU6ZMgZWVFXr37g21Wt1iLU899RQ2b96MxYsX49SpUwgNDcXp06eRmJiInj17ttsM8okTJ7BkyZJm2+VyOZ5++mm88cYbmD17NmbOnInHHnsMbm5u2LlzJ/bs2YPJkydj6NChAOpbm9566y3ExcWhZ8+eUKlUOHHiBBITExEZGWkM5xMnTkT//v0REREBd3d3lJaWIiEhAQqFApMmTWqX75GIWscy38WIiG7iySefhCAISExMxHvvvQc3NzdMmDAB8fHxmDhxotjlNaNUKvHtt9/igw8+wI4dO7Bp0yZERETgm2++wRtvvIHq6mqzzvPee+8hOjoaa9euxYoVK1BXVwcfHx+MHz8e8+bNg1KpxPTp0/HKK6/Azs4OI0aMMOu8U6ZMwQcffICamppmF3gC7fd6v/HGG3B1dUVCQgI++OADBAYG4u2330ZOTk6ziyv/9a9/4aOPPkJKSgp++uknBAYGYsGCBZDL5Vi4cKHJvgMHDsTLL7+MtWvX4q233oJOp8Pzzz9/01BuZ2eHNWvW4LPPPkNKSgqSkpLg4uKCGTNm4IUXXmj1XWTNdfTo0RZXrlEqlXj66acRHh6OtWvX4rPPPsOaNWug1Wrh5+eHl19+GfPmzTPuHxISgrFjx2Lfvn3YsGEDDAYDvLy88Mwzz5jsN2/ePOzatQvfffcdKisr4eLigsjISDzzzDMmK7wQkXgkQkdcpUNERCb0ej2GDBmCiIiIO74BDxERdR3sKSciamctzYavXbsWFRUVLa7LTURE3Q/bV4iI2tmbb76J2tpaREVFQalU4vDhw0hOTkZAQAAeeeQRscsjIiILwPYVIqJ29vPPP2PVqlXIzs6GVquFi4sLRo4ciZdeegmurq5il0dERBaAoZyIiIiISGTsKSciIiIiEhlDORERERGRyHihZ4MrVzQwGDq2k8fFxRZlZVUd+pxEnRHHCpF5OFaIzCPWWJFKJXByUrX4GEN5A4NB6PBQ3vi8RHR7HCtE5uFYITKPpY0Vtq8QEREREYmMoZyIiIiISGQM5UREREREImMoJyIiIiISGUM5EREREZHIGMqJiIiIiETGUE5EREREJDKGciIiIiIikTGUExERERGJjHf0FMHek0VI2pWFyxU1cLa3wtSRQRga5il2WUREREQkEobyDrb3ZBG+3XQGtToDAKCsogbfbjoDAAzmRERERN0U21c6WNKuLGMgb1SrMyBpV5ZIFRERERGR2BjKO1hZRU2rthMRERFR18dQ3sFc7K1a3C4B8NvhfBgEoWMLIiIiIiLRMZR3sKkjg6CUm77sCpkUns49sHJLBt5beRA5RZUiVUdEREREYuCFnh2s8WLOG1dfGdLXA2mnivHDjkws/nY/Ygf44qF7esHGmn9FRERERF2dRBDYLwEAZWVVMBg69qVwc7NDaanprLi2ug7rdp/Hb4fyYa9SYvqYYMSEekAikXRobUSWpKWxQkTNcawQmUessSKVSuDiYtvyYx1cC92GjbUCs+NC8Objg+BoZ4Uv15/Ch2uPoLBMI3ZpRERERNROGMotVE8ve7w1ZxBmxamRXVSJd/67D0m7z6O2Ti92aURERETUxtiwbMGkUgliB/hiYIg7ElIykZyajbSTRZg5Vo3IYFexyyMiIiKiNsKZ8k7AQaXE/ClhePXRKCjkUnyaeAxfJB1HWXm12KURERERURtgKO9E+gQ4YdG8aMSP7IUT58vwxvI0bErPgU5vuP3BRERERGSx2L7SychlUkwaGoiYUA+s3p6JH3dmIfV4EWbFqRHi7yR2eURERER0BzhT3km5OvbAi9Mi8EJ8OKpr9Xh/9WGsSD6FCk2t2KURERERUStxpryTi+rthr4Bzkjem43N6bk4cu4S4kcG4d7+3pBybXMiIiKiToEz5V2AlVKG+JFBWDQvGn7utli5JQPvrTyInCLeQIKIiIioM2Ao70K8XVV45dEozJ/SF2Xl17D42/1Yte0stNU6sUsjIiIioltg+0oXI5FIMDTME5FBLkjafR4pB/Nw4EwJpo8JRkyoByRsaSEiIiKyOJwp76JsrBWYFReCNx8fBCc7K3y5/hQ+XHsEhWUasUsjIiIiohswlHdxPb3s8eacQZgVp0Z2USXe+e8+JO0+j9o6vdilEREREVEDtq90A1KpBLEDfDEwxB0JKZlITs1G2skizByrRmSwq9jlEREREXV7nCnvRhxUSsyfEoZXH42CQi7Fp4nH8EXScZSVV4tdGhEREVG3xlDeDfUJcMKiedGIH9kLJ86X4Y3ladiUngOd3iB2aURERETdEttXuim5TIpJQwMRE+qB1dsz8ePOLKQeL8KsODVC/J3ELo+IiIioW+FMeTfn6tgDL06LwAvx4aiu1eP91YexIvkUKjS1YpdGRERE1G1wppwAAFG93dA3wBnJe7OxOT0XR85dQvzIINzb3xtSrm1ORERE1K44U05GVkoZ4kcGYdG8aPi522Lllgy8t/IgcooqxS6NiIiIqEtjKKdmvF1VeOXRKMyf0hdl5dew+Nv9WLXtLLTVOrFLIyIiIuqS2L5CLZJIJBga5onIIBck7T6PlIN5OHCmBNPHBCMm1AMStrQQERERtRnOlNMt2VgrMCsuBG8+PghOdlb4cv0pfLj2CArLNGKXRkRERNRlMJSTWXp62ePNOYMwO06N7KJKvL1iH5J2Z6G2Ti92aURERESdHttXyGxSqQSjB/hiQIg7ElLOITk1B2knizFzrBqRwa5il0dERETUaXGmnFrNQaXE/Cl98eqjUVDIpfg08Ri+SDqOsvJqsUsjIiIi6pQYyumO9QlwwqJ50Ygf2QsnzpfhjeVp2JSeA53eIHZpRERERJ0K21forshlUkwaGoiYUA+s3p6JH3dmIfV4EWbFqRHi7yR2eURERESdAmfKqU24OvbAi9Mi8EJ8OKpr9Xh/9WGsSD6FCk2t2KURERERWTzOlFObiurthr4Bzkjem43N6bk4cu4S4kcG4d7+3pBybXMiIiKiFnGmnNqclVKG+JFBWDQvGn7utli5JQPvrTyInKJKsUsjIiIiskgM5dRuvF1VeOXRKMyf0hdl5dew+Nv9WLXtLLTVOrFLIyIiIrIobF+hdiWRSDA0zBORQS5I2n0eKQfzcOBMCaaPCUZMqAckbGkhIiIiEjeUl5SUYOXKlTh69ChOnDgBrVaLlStXIiYm5pbHGQwG/PTTT9i2bRtOnz6N8vJy+Pr6YvLkyZg3bx6USmUHfQdkLhtrBWbFhWB4uBe+25KBL9efwu9HCzErTg0vF5XY5RERERGJStT2lQsXLuCrr75CcXExQkJCzD7u2rVreP3113HlyhXMmDEDr7/+OsLDw/Hpp5/i6aefbseK6W719LLHm3MGYXacGtlFlXh7xT4k7c5CTZ1e7NKIiIiIRCPqTHlYWBjS0tLg5OSE7du347nnnjPrOIVCgTVr1mDAgAHGbY888gh8fHzw+eefIz09/baz7SQeqVSC0QN8MSDEHQkp55CcmoO0k8WYOVaNyGBXscsjIiIi6nCizpTb2trCyan1N5hRKpUmgbzR2LFjAQBZWVl3XRu1PweVEvOn9MWrj0ZBIZfi08Rj+HzdMZSVV4tdGhEREVGH6lIXel66dAkA7ijod6R9RYewPmszrtZchaOVI+4PGo9oz+a/ZHQXfQKcsGheNLbuv4j1ey7gjeVpeGBET4wd5Ae5jAsEERERUdfXpUL58uXLYWdnhxEjRohdyk3tKzqE1WfWoc5QBwC4UnMVq8+sA4BuHczlMikmDglAdKg71mzPxI87s5B6vAiz4tQI8bfsX7KIiIioc7DkidEuE8qXLVuG1NRULF68GHZ2dq0+3sXFth2qau7XtK3GQN6ozlCH5AtbMCl8ZIfUYMnc3OywONgd+04W4T8/HcP7qw8jdpAf5k4Og6OdldjlkYjc3Fo/rom6I44Vopb9nrMPazKSUKuvBVA/MbomIwn29j1wT0C0yNV1kVC+ceNGfPLJJ5g+fTqmT59+R+coK6uCwSC0cWXNXdJebvn5r13Bi8l/h6+tF3xtvev/s/OGnbJjflmwND3dVVg0NxrJe7OxOT0X6ScKET8yCPf294aUa5t3O25udigt5R1hiW6HY4XEZhAM0AsG6A16GAQ99IIBOoOufpugh96gb/izDnpDwzbjdr3xWNPtBtN9mm5r+Fon6KE3GBqes/4/nUFvUktuZT70gulqb7X6Wnx/+Cf0sQntkNdHKpXcdCK404fyP/74A6+++ipGjx6Nd955R+xybsvJyhFXaq42224ts4ZbD2dkXc3GgeIjxu0OSjv4NAT0xsDuZuMKqaTr91pbKWWIHxmEoWGe+H5rBlZuycDvxwoxZ1wIAjw5E0RERF2LwSSQGqAzBtvrQVTXJMwaGoKoTtDdEGYN0LcUhJtuazi2WThuut9tzqcTdDDccKxBMLT76ySBBDKpDDKJFDKJrP4/aeP/W9gmkUIhtWoWyBu1lMvE0KlD+dGjR/H8888jPDwcH3/8MWQymdgl3db9QeNNesoBQCFVYHrIg8aeJk2dFvlVBcirLEBeVSHyqgpwJjfT+A9dKVXA29arPqTb1c+qe9t6wUrWNW+a5O2qwiuPRiHtVDF+2JGJxd/uR+wAXzx0Ty/YWHfqf8JERG3CkvtkO4IgCNdnaE1mXfW3nI3VGYOtaRBu3N9gaL6tfruhYWZWf0OYvc2sb9N6WjhWQPt/Yi+VSFsOsxJpk2DbZJtEBqVM2WS7+UG48c9yiQzSpsdK67c1Hitt+LPcjFpkUtkdT0y++cc/WgzgTlaOd/uytolOkWhyc3MBAP7+/sZtWVlZePrpp+Hj44Nly5bB2tparPJapfGH5K1+eKoUNlA7BUPtFGzcVmfQoUhTgryqAuRXFiCvqgAHS45iT0E6gPrfGt1sXExaX3xtvWGvtOsSt7KXSCQYGuaJyCAXJO0+j5SDeThwpgTTxwQjJtSjS3yPRER34m4XEGgMtM1CZuMs6h3OwLY0i9q0jeF64DU9tvEY3Q2h1WBsUWhSS5OvO4K0SSCVN4RMaZPgKG8SPKUSGeRSOaxlViahVdp0P2PgvCHwmmy/TYBuOJ/0xiDcZF9pk/N3h0/ab+ZmE6P3B40XsarrJIIgtP+vZbewZMkSAPUhOzk5GfHx8fD19YW9vT1mzZoFAIiNjQUApKSkAACqqqowefJkFBcXY8GCBfDw8DA5Z0hICPr06dOqOjqqp7ypu+39EwQBl6uvIq+qoElYL0RZ9fW+dVuFyiSk+9p5w72HK2RSy/9U4VYuFFbguy0ZyC6qRGiAE2bFqeHlohK7LGon7JMlas4gGHC5+gr+deALVNVpmj0uk8jgqXK/Hm5NenybzPp2QLtBYz31oVF+Q/i8YVtDEJVL5JA2DaQSKeQN+0mlzbcZQ2/DsbIbjjU+h7SFbSahWN4sCMsl9bOznADq/MT+VOlWPeWih/KQkJAWt/v4+BhD+I2hPC8vD2PGjLnpOZ9//nm88MILraqjM4bym9HWXUN+Q9tLXlUB8qsKUVhVBF3DTIJCKoeXytMkrPvYesJa3jk+bWhkMAjYdSQfibvOo7ZOjwlD/DFpaCCsFJ37Fw5qjqGcujO9QY/Sa2Uo0hSjUFOCIm0xijQlKNaWoM6gu+WxEa5hrZ+Rbbqt4Vi5sW2ghSB80zDbsK1hdpaBliyJWO8rFh3KLUVXCuUt0Rv0KNKWNPSp1wf1vMoCaHRa4z6uPZq2v9RfVOpo5WDxP0jLNbVISDmHvSeL4OpgjZlj1YgMdhW7LGpDDOXUHdTp61By7RIKNcUo0tQH70JtCUq1l0zaM5ytneCpcoeXjQc8Ve5Yf34zKmurmp3PycoR/2/46x35LRB1GgzlFqyrh/KWCIKAqzXl9TPqlYX1F5dWFaD0WplxH5XcBj5NVn7xtfOGp427Rba/nMm5gu+2ZqCwTIuo3q547D41XBw61+w/tUzssULUlqp1NSjWltSHbk0xirQlKNIU49K1y8YL/SSQwK2HCzxV9cHb08YdXioPuNu4wVpues+GG3vKgfo+2cf6xHeriz2JWoOh3IJ1x1B+M9W6auRXFTXMqNcH9gJNofFjUrlEBi+VR0NYrw/sPrbesFH0ELlyQKc3YOv+i1i/5wIgAR4Y3hNjB/tBLuu+F7Z0BZY6VohuRVunRZG2IXhrrofwpqs/yCQyuNu41odvG3d4qdzhqfKAew9XKGQKs59L7D5Zos6GodyCMZTfmt6gR8m1S8irLDD2q1+szDe5uMjF2qm+P73JzLqztZMo7S+Xyq9hzfZMHM68BAGkVqkAACAASURBVG9XFWbHqRHi79ThdVDb6ExjhboXQRBQWVfVELobe77r/1xRe/3frEKqgKeN2/WZb5UHvGzc4drDpU0/eeRYITIPQ7kFYyhvPUEQUFFb2bDyy/ULS0u0l4wfwfaQWxv71H0a1lX3VHlAIe2Y1TiPZF7Cqm1nUVZRjWH9PPHI6GDYq7rmeu5dWWcfK9T5Nbb71fd5X+/5LtKUmFybYy2zatZy4qnygLO1Y4csRcexQmQehnILxlDedmr0tSioKjTe+Ci/YXa9tqHfUSqRwkvlcT2o23rDx84Ltor2WdKwpk6P5NRsbE7PhXXDXULv7e8NqYVfwErXddWxQpbHIBhQdu2KcYWTxp7vYk0JqvU1xv1UCht42ngY2008VfUB3EFpL+rF8RwrROZhKLdgDOXtyyAYUKq9ZAzqjWG9vMnHu05WjvC1q+9Pb5xdd+nh1GazSwWXNPh+awbO5F5FTy97zBkXggBPuzY5N7Wv7jRWqGPULzN4qSF433yZQQelXUPoNu35tlO2/KYqNo4VIvMwlFswhnJxVNZWNaz+UtAQ1gtRrCkxtr9Yy6zg03AhaeMyjV4qTyhbcQFUU4IgIO1UMX7YkYnKa3WIHeCLh+7pBRvrTnFz226LY4XuVJ2+DsXaUmOfd2PPd4m21OSmOTcuM9gYwi3hAvbW4FghMg9DuQVjKLcctfo6FGqKjEs1Nq4CU6OvBVDf/uJh42ZsfWm8AVJrZq601XVI2n0eOw/lw16lxPQxwYgJ9bD4Ndm7K44Vup3mywzWz3ybs8ygh8odVrKuca0JxwqReRjKLRhDuWVr7PNsbH1pnFm/WlNu3MdBaQ+fhtn0xrDu1sPllu0vFwor8N2WDGQXVSI0wAmz4tTwcmmf3na6cxwr1EhbpzVpN2lcbvBmywx62bgbZ75bu8xgZ8SxQmQehnILxlDeOVXVaUxWfsmrLECRtsT4sbRSpoSPyrPJmure8LH1hLLJrJjBIGDXkXwk7jqP2jo9Jgzxx6ShgbBSWN4NkrorjpXu5foyg8XXe74bLri8+TKDDRdbtsMyg50JxwqReRjKLRhDeddRZ9ChSFPcpE+9fvWXa7pqAPUfYbvbuF4P6Q2BHTorJKScw96TRXB1sMbMsWpEBruK/N0QwLHSVTUuM9j0rpaFmvqVTkyXGbRumO1uWGLQxr1DlxnsTDhWiMxjiaGcV7dRl6OQyuFn5wM/Ox/jNkEQcLn6SpPWl0JkV+TiYMlR4z52Clv4+nljuI8zzmTo8VnyJUT6+WPmfX3g4mAtxrdC1CW0uMxgQwtK47UiwPVlBqPcwy1qmUEioo7AmfIGnCnvnrR12oY7lBY23K20AAWaYugFPQBAMEiBa3YIsPdBdM/eCHDwgbfKE9ZyhvSOxLHSOTQuM1jYcFOdIm0xCjXFKNGW3rDMoP31u1o2XHBpycsMdiYcK0Tm4Uw5kYWxUdigt1MQejsFGbfpDDoUa0uRV1mAzLJcHM2/gJyaTOSeO2Xcx62Hi8nKLz62XnC0cuBsHnULxmUGG9pOGnu+S65dMllm0MXaCR4qd/Rx6m2y4klnW2aQiKgjMJQT3UAulTesje6FGK+BmNUPOHy2FN//dhTlhksIDBTg7FSDi1UFOFx63HicSmFjsvKLj60XPG3cu+0FZ9T5VeuqUawtNWk3KdSUoOzGZQZtXOBp44EItzBjz3dXWmaQiKgjMJQTmSFK7Ya+PUcjOTUbm9NzUaSQIX7UWEQPdEahtsh4h9K8qkLsyk+FruGjerlEBi9bzyYrv3jB184LPeScKSTLoanT1odu48x3y8sMeti4wc/OB9EeUcaZb3cbNyikfCshIrpb7ClvwJ5yMlfBJQ2+35qBM7lX0dPLHnPGhSDA0874uN6gr29/aVz5pWHJxqo6jXEfF2vnhtaXhruV2nrD2dqR7S83wbFy95ouM2js+dYUo1BbjMraKuN+CqnC2GbStOe7Oy8z2JlwrBCZxxJ7yhnKGzCUU2sIgoC0U8X4IeUcKrW1iB3gi4fu6QUb65ZnDAVBQHlthXHll/yGwF6qLTO2AfSQ94CvrVdD60t9UPdSuUPOWUiOlVYwWWbwhp5vre6acT9rmTW8VPVtJlxmsOvgWCEyD0O5BWMopzuhra5D0u7z2HkoH/YqJaaPCUZMqIfZM97VuhoUaIqMK7/UB/ZC1BnqANS3DHiq3BvaX64HdpXCpj2/LYvDsdJc02UGjT3fN1lmsGno5jKDXRvHCpF5GMotGEM53Y0LhRX4bksGsosqERrghFlxani5qO7oXAbBgBLtJeNNjxpvgtT0ToZOVo7G9pfGC0tdrJ27bMjqzmNFZ9Ch9FrZ9XaThtnvYm2p8doFoH6ZQS+VR8PMtzs8beoDOJcZ7F6681ghag2GcgvGUE53y2AQsOtIPhJ3nUdtnR4Thvhj0tBAWCnapg+3vKYS+Y1BveEmSMXaUmP7i7XM2nghqa+x/cUDCpmiTZ5fTN1hrNQ2LDNYrClGYcPdLYs0JS0uM+jZZObbS+UODy4zSA26w1ghagsM5RaMoZzaSrmmFgkp57D3ZBFcHawxc6wakcGu7fJctfpaFGiKjBeT5jW0wNQ2tC9IJVJ42rg3hPXrK8B0ttnTrjRWqnXVDbeUL7l+d0vtzZcZNN5aviF8c5lBupWuNFaI2hNDuQVjKKe2dibnCr7bmoHCMi2iervisfvUcHFo/zuBGgQDLl0rq+9Pr7we1K/WlBv3cbRyqA/qxhsgecG1h4vFXuDXGcdK02UGC7XXe75bWmbQQ+UOryY931xmkO5UZxwrRGJgKLdgDOXUHnR6A7buv4j1ey4AEuCB4T0xdrAf5LKOD79VtZrrs+mV9SvAFGlLjK0RSpkSPiqv673qdt7wVnlCaQEzs5Y6VgRBQEVtFYq1xcYVToo0JVxmkERjqWOFyNIwlFswhnJqT5fKr2HN9kwczrwEb1cVZsepEeLvJHZZqNPXoVBbjLzK633q+VWFqNZXA6hvo3C3cTOG9MaZdXul3W3O3LbEHiuCIOBKzdUmF1uWNLSgcJlBsixijxWizoKh3IIxlFNHOJJ5Cau2nUVZRTWG9fPEI6ODYa8Sfya6KUEQUFZ9xRjSG//ftO3CTmlrvJi0May727i2W/DsqLFS3/pzGcVN7mrZ0jKDtgrVDTPf9W0nXGaQxMb3FSLzMJRbMIZy6ig1dXokp2Zjc3ourBQyxI8KwshIb0illh3mNHVak5Vf8qsKUagphl7QA6hv0fC29TQJ694qT1jLre76udt6rDQuM1ioKUZxk4stucwgdXZ8XyEyD0O5BWMop45WcEmD77dm4EzuVfT0sseccSEI8OzYtpC7pTPoUKQpMfaqN64C09jSIYEEbj1c4NPY+tLQBtPaGeU7HSuNyww23tmysfWklMsMUhfF9xUi8zCUWzCGchKDIAhIO1WMH1LOoVJbi9goXzx0by/YWHfelTca+68bW18ab4B0qfqycR9bhap+ecYma6p72Lg1u+hxX9EhrM/ajKs1V+Fo5Yj7g8Yj2nNAs+dsXGawUFNyfeZbU4yy6ivNlhn0svG43vPNZQapi+H7CpF5GMotGEM5iUlbXYek3eex81A+7FRKzIgNRkxfjy7Vn3xNdw35VUUNrS/1gb1AU2xsF5FL5fBWeTSEdW9U1lRhx8XdqDPUGc+hkCowxu9eOFk7GNf6LtQUmyz32LjM4I093242rlxmkLo8vq8QmYeh3IIxlJMlyC6qwMrNGcguqkRogBNmxanh5aISu6x2ozfoUawtNWl/uViVD02d9rbHXl9msPEGO/UB3NXamcsMUrfF9xUi8zCUWzCGcrIUBoOAXUfykbjrPGrr9JgwxB+ThgbCStE9gqYgCCivrcAbf7x3030WD30NTlxmkKgZvq8QmccSQzk/yyWyMFKpBKMH+GJAiDsSUs4hOTUHaSeLMXOsGpHBrmKX1+4kEgkcrRzgZOVosgxjIycrR7j0cBahMiIiovbDaSYiC+WgUmL+lL549dEoKORSfJp4DJ+vO4ay8mqxS+sQ9weNh0KqMNmmkCpwf9B4kSoiIiJqP2xfacD2FbJkOr0BW/dfxPo9FwAJ8MDwnhg72A9yWdf+vdrc1VeIqB7fV4jMY4ntKwzlDRjKqTO4VH4Na7Zn4nDmJXi7qjA7To0Qfyexy2p3HCtE5uFYITKPJYbyrj3NRtTFuDr0wAvxEXgxPgI1tXq8v/owliefQoWm9vYHExERkcXihZ5EnVD/3q4IDXRCcmo2Nqfn4kjmJcSPCsLISG9IpV1nbXMiIqLugjPlRJ2UlUKG+JFBWDQvGv4etvhuSwbe++4gcor40TUREVFnw1BO1Ml5u6rwyqNRmD+lL8oqqrH42/1YtfUstNU6sUsjIiIiM7F9hagLkEgkGBrmicggFyTtPo+UQ3nYn1GCGbHBiOnrAYmELS1ERESWjDPlRF2IjbUCs+JC8NYTg+BsZ4UvN5zCh2uPoLBMI3ZpREREdAsM5URdUKCnPd6cMwiz49TILqrE2yv2Yd2uLNTU6cUujYiIiFrA9hWiLkoqlWD0AF8MCHFHQso5/Lo3B+mnivHYWDX6B7uKXR4RERE1wZlyoi7OQaXE/Cl98bfHoqCQS/FZ4jF8vu4YysqrxS6NiIiIGjCUE3UTIf5OWDQvGtNGBeHkhct4Y3kaNqXlQKc3iF0aERFRt8f2FaJuRC6TYuKQAESHumPN9kz8+FsW/jhRhNlxaoT4O4ldHhERUbfFmXKibsjVoQdeiI/Ai/ERqKnV4/3Vh7E8+RQqNLVil0ZERNQtcaacqBvr39sVoYFOSE7Nxub0XBzJvIT4UUEYGekNqZRrmxMREXUUzpQTdXNWChniRwZh0bxo+HvY4rstGXjvu4PIKaoUuzQiIqJug6GciAAA3q4qvPJoFOZP6Yuyimos/nY/Vm09C221TuzSiIiIujy2rxCRkUQiwdAwT0QGuSBp93mkHMrD/owSzIgNRkxfD0gkbGkhIiJqD5wpJ6JmbKwVmBUXgreeGARnOyt8ueEUPlx7BIVlGrFLIyIi6pJEDeUlJSX48MMPMXv2bERFRSEkJATp6elmH5+VlYUnn3wSUVFRiI6Oxt/+9jdcvny5HSsm6l4CPe3x5pxBmB2nRnZRJd5esQ/rdmWhpk4vdmlERERdiqjtKxcuXMBXX32FgIAAhISE4PDhw2YfW1RUhJkzZ8Le3h4LFiyAVqvFf//7X5w9exYJCQlQKBTtWDlR9yGVSjB6gC8GhLgjIeUcft2bg/RTxXhsrBr9g13FLo+IiKhLEDWUh4WFIS0tDU5OTti+fTuee+45s49dtmwZampq8N1338HDwwMAEBERgblz5+KXX37BtGnT2qtsom7JQaXE/Cl9cW+kF1ZuycBniccQ1dsVj92nhouDtdjlERERdWqitq/Y2trCyenO7iK4detWxMbGGgM5AAwbNgyBgYHYtGlTW5VIRDcI8XfConnRmDYqCCezL+ON5WnYmJYDnd4gdmlERESdVqe80LO4uBhlZWXo169fs8ciIiJw+vRpEaoi6j7kMikmDgnA/3sqBmGBzkj8LQt//3o/MnKviF0aERFRp9QpQ3lJSQkAwM3Nrdljbm5uKCsrg17PC9GI2purQw+8EB+BF+MjUFOrx/urD2N58ilUaGrFLo2IiKhT6ZTrlNfU1AAAlEpls8esrKwAANXV1VCpVGaf08XFtm2KayU3NztRnpeoLY11s8M9g/yQsP0sfvrtHI5mleHxiaGIGxIImbRt1jbnWCEyD8cKkXksbax0ylDeGLxra5vPxjUGdmvr1l14VlZWBYNBuPviWsHNzQ6lpbyVOXUdEwb7IbKnM77fmoEl645hU2o25owLQYDn3f3g41ghMg/HCpF5xBorUqnkphPBnbJ9xd3dHQBQWlra7LHS0lK4uLhAJpN1dFlEBMDbVYVXHo3C/Cl9UVZRjcXf7seqrWehrdaJXRoREZHF6pQz5R4eHnB2dsaJEyeaPXbs2DGEhoaKUBURNZJIJBga5onIIBck7T6PlEN52J9RghmxwYjp6wGJpG1aWoiIiLqKTjFTnpubi9zcXJNtcXFxSElJQXFxsXHb3r17kZ2djfHjx3d0iUTUAhtrBWbFheCtJwbB2c4KX244hQ/XHkFhmUbs0oiIiCyKRBCEjm2kvsGSJUsAAFlZWUhOTkZ8fDx8fX1hb2+PWbNmAQBiY2MBACkpKcbjCgsL8eCDD8LR0RGzZs2CVqvFihUr4OXlhR9//LHFi0BvhT3lRO3LYBCw60g+EnedR22dHuNj/DF5WCCsFLdvNeNYITIPxwqReSyxp1z0UB4SEtLidh8fH2MIbymUA0BmZib++c9/4uDBg1AoFBg1ahQWLlwIZ2fnVtfBUE7UMco1tUhIOYe9J4vg6mCNx8aq0T/Y9ZbHcKwQmYdjhcg8DOUWjKGcqGNl5F7Byi0ZKCzTIqq3Kx67Tw0Xh5ZXTeJYITIPxwqReSwxlHeKnnIi6npC/J2waF40po0Kwsnsy3hjeRo2puVApzeIXRoREVGH65SrrxBR1yCXSTFxSACiQ92xZnsmEn/LQuqJIsyOUyPE30ns8oiIiDoM21casH2FSHxHMi9h9fazuFRejWH9PNHL2x6b0nJwuaIGzvZWmDoyCEPDPMUuk8hi8X2FyDyW2L7CmXIishj9e7siNNAJyanZ2Lg3B6knioyPlVXU4NtNZwCAwZyIiLoc9pQTkUWxUsgQPzII9rbNlzWt1RmQtCtLhKqIiIjaF0M5EVmk8qraFreXVdSAXXdERNTVMJQTkUVysbe66WPv/Hc/9p8pgYHhnIiIugiGciKySFNHBkEpN/0RpZRLMaq/N+r0Biz9+QTeXrEPaSeLOvwibSIiorbGCz2JyCI1XsyZtCur2eorBoOA/WdKkJyajS83nMIvey5g8rBAxPT1gFzGuQYiIup8uCRiAy6JSGS5bjZWDIKAQxml2JCajYslVXB1sMbkYYEY1s+T4Zy6Jb6vEJmHSyISEbUhqUSCQX3cMTDEDUfPlWFD6gV8s+kMNvxxAROGBOCeCC8o5DKxyyQiIrothnIi6vQkEgn693ZFZLALTly4jA1/ZOP7rWeRnJqNCTEBuLe/N6wUDOdERGS5GMqJqMuQSCQI7+WCfj2dcSbnCtb/kY01OzLx695sjI8JwKgob1gr+WOPiIgsT5u8O+l0OuzYsQPl5eUYPXo03Nzc2uK0RER3RCKRIDTQGaGBzsjIvYINqdlI2HkOG9NyEDfYD2MG+qKHFcM5ERFZjla/K33wwQdIT0/HunXrAACCIGDu3Lk4cOAABEGAo6MjEhIS4O/v3+bFEhG1Voi/E0L8nXAuvxzJqdlI2n0em9NzMXawH+4b5AuVtULsEomIiFq/Tvnvv/+OQYMGGb9OSUnB/v378eSTT+Kjjz4CAHz55ZdtVyERURsI9nHAXx6OxFuPD0KIvyN+2XMBry5NxbpdWajUtnz3UCIioo7S6pnyoqIiBAQEGL/euXMnfH198fLLLwMAMjMzsWHDhrarkIioDfX0sscL8RHILa5Ecmo2Nu7NwfYDeRg9wAfjov3hoFKKXSIREXVDrQ7ldXV1kMuvH5aeno5hw4YZv/bz80NpaWnbVEdE1E78Pezw54fCkX9Jg19Ts7FlXy5SDuZhZH8fjI/xh5OdldglEhFRN9Lq9hVPT08cPnwYQP2s+MWLFzF48GDj42VlZbCxsWm7ComI2pGPqwpP3x+G9+YPweA+7thxMA9/W7YX32/NwOWKarHLIyKibqLVM+WTJk3CkiVLcPnyZWRmZsLW1hYjR440Pn769Gle5ElEnY6nsw2enNwXU0b0xMa92dh1pAC7jhRgeLgXJg0NgJtjD7FLJCKiLqzVofyZZ55BYWEhduzYAVtbW7z//vuwt7cHAFRWViIlJQVPPPFEW9dJRNQh3B174IkJoZgyrCc2pufg96MF2HOsEEP7eWDy0EB4OPOTQCIiansSQRCEtjqZwWCARqOBtbU1FIrOtcxYWVkVDIY2eynM4uZmh9LSyg59TqLOSMyxcqWyBpvSc7DrSAF0egNi+taHc29XlSj1EN0K31eIzCPWWJFKJXBxsW3xsTa9e4ZOp4OdnV1bnpKISFROdlZ47D41Jg0JwJZ9F5FyOA/pJ4sxsI87pgwLhJ97yz9ciYiIWqPVF3ru2rULn3/+ucm2VatWYcCAAejfvz/++te/oq6urs0KJCKyBA62VngkNhj/+tMwTBwagBPny/DOf/fh83XHkFPEmUkiIro7rZ4pX7FiBVxcXIxfZ2Vl4R//+Af8/Pzg6+uLjRs3Ijw8nH3lRNQl2dkoET8yCOOi/bH9wEVsP5CHRZn7ERHkginDAxHk7SB2iURE1Am1eqb8/Pnz6Nevn/HrjRs3wsrKComJiVi+fDkmTpyIn3/+uU2LJCKyNLY9FHjwnl744E/D8NC9vZCVX473Vh7ERz8cwdmLV8Uuj4iIOplWh/Ly8nI4OTkZv05NTcWQIUNga1vfVxkdHY28vLy2q5CIyILZWMsxZVgg/vXnYXh4dBAuFlfin6sO4YPVh3A65wra8Fp6IiLqwlodyp2cnFBQUAAAqKqqwvHjxzFo0CDj4zqdDnq9vu0qJCLqBKyVckyICcD7fxqGGWN6o/CyFv9acxj/u+oQTpwvYzgnIqJbanVPef/+/bF27VoEBwdj9+7d0Ov1uPfee42P5+TkwN3dvU2LJCLqLKwUMsQN9sPoKG/sPlqIjWk5+HfCUfT0sseU4YGIDHKBRCIRu0wiIrIwrQ7lL774IubMmYO//OUvAICHHnoIwcHBAABBELB9+3bExMS0bZVERJ2MQi7DmIG+uDfSG3+cKMTGvTn4LPEY/D1sMWVYIKLUbpAynBMRUYM7unnQ1atXcejQIdjZ2WHw4MHG7eXl5fj5558RExODPn36tGmh7Y03DyKyXF1hrOj0BqSdLEby3myUXLkGHzcVpgwLxKAQd0ilDOfUNrrCWCHqCJZ486A2vaNnZ8ZQTmS5utJY0RsM2He6BMmp2Sgs08LLxQaThwYiuq87ZNJWX+ZDZKIrjRWi9mSJofyO7+iZm5uLHTt24OLFiwAAPz8/jBkzBv7+/nd6SiKiLk8mlWJomCdiQj1wIKM+nH+VfAq//HEBk4YGYGiYJ+QyhnMiou7mjmbKP/nkE3z11VfNVlmRSqV45pln8NJLL7VZgR2FM+VElqsrjxWDIOBI5iVs+CMbOcWVcHWwxsQhARge7gWFnOGcWqcrjxWittQlZsoTExOxbNkyREVF4amnnkLv3r0BAJmZmVixYgWWLVsGPz8/TJ069e6qJiLqBqQSCQao3RDV2xXHssqwITUbK7dkYENqNiYOCcC9kV5QyGVil0lERO2s1TPlU6dOhUKhwKpVqyCXm2Z6nU6HmTNnoq6uDklJSW1aaHvjTDmR5epOY0UQBJzMvowNf2QjM68cDiolJsT4Y2SUD6wUDOd0a91prBDdDUucKW/1Z6NZWVmYOHFis0AOAHK5HBMnTkRWVlbrqyQiIkgkEvTr6YLXZg7Aq49GwcvFBmtTzuHVpanYmJaDazU6sUskIqJ20Or2FYVCAa1We9PHNRoNFArFXRVFRNTdSSQS9AlwQp8AJ2TmXcWGP7KR+FsWNqXlIG6wH8YM9ION9R1fq09ERBam1TPl4eHh+OGHH3Dp0qVmj5WVlSEhIQGRkZFtUhwREQG9fR3xP9P74805gxDs44Cffr+AV5am4uffz6PqWp3Y5RERURtodU/5/v378cQTT0ClUiE+Pt54N89z584hKSkJGo0G33zzDQYNGtQuBbcX9pQTWS6OFVM5RZXYkJqNQ2dLYa2sv3Po2MF+sLdRil0aiYxjhcg8lthTfkdLIqakpODdd99FYWGhyXZvb2+8/fbbGDVq1B0VKiaGciLLxbHSsrySKiTvzcb+0yVQKKQYHeWD8dH+cLC1Ers0EgnHCpF5ukwoBwCDwYATJ04gLy8PQP3Ng8LCwpCQkICVK1di48aNd16xCBjKiSwXx8qtFVzS4Ne92Ug7VQy5TIqRkd6YMCQATnYM590NxwqReSwxlN/xVUJSqRQRERGIiIgw2X7lyhVcuHDhTk9LRESt5O2qwvwpYbh/eE/8ujcHOw/n47cj+RgR4Y2JQ/zh6tBD7BKJiOg2eOk+EVEX4eFsg3mTQjFleCA2puXg96MF+P1oAYb188SkoQFwd7IRu0QiIroJhnIioi7GzbEHHh/fB1OGBWJTWi52HS3AH8eLMCTMA5OGBsDLRSV2iUREdAOGciKiLsrZ3hoz49SYNCwAm9Nz8dvhfOw9UYTBoe6YMiwQPm4t9zUSEVHHYygnIuriHG2tMGNMb0wcEoAt+3ORcjAf+06XYGCIG6YMC4S/h53YJRIRdXtmhfKvv/7a7BMeOnTojoshIqL2Y69S4uFRwZgQE4Ct+y9ix8GLOJhRiv7BrpgyPBA9vezFLpGIqNsya0nEPn36tO6kEglOnz59x0WJgUsiElkujpX2oa2uw/YDedh24CI01TqE93LBlOGBCPZxELs0ukMcK0Tm6bRLIq5cubJNCyIiIvHZWCtw/4ieGDvYDymH8rBl30X847uDCA1wwv3DAxHi7yR2iURE3cYd3zyoq+FMOZHl4ljpGDW1euw8nI/N+3JRoamF2s8RU4YHom+AEyQSidjlkRk4VojM02lnyomIqOuzUsowPsYfsQN8sOtoATal5eCjtUcQ5G2PKcN7IryXM8M5EVE7YSgnIiITSoUMYwf5YVR/b+w5VoiNaTn45MejCPS0w5Rhgejf25XhnIiojYkaymtra/Hpp5/il19+QUVFBfr06YMFCxZg6NChtz02NTUVS5cuxdmzZ2EwGNCrVy88/vjjmDhxYgdUTkTU9SnkMowe4It7Ir2R/jDvyQAAIABJREFUeqIIv+7NxudJx+HnbospwwIxIMQNUoZzIqI2IRXzyV977TV8++23uP/++/HGG29AKpVi/vz5OHz48C2P27lzJ+bNmwedTocXXngBL730EqRSKRYsWIAff/yxg6onIuoe5DIp7o30xj+eHoInJ4WiVmfAkp9P4J0V+5B2qqjDr8chIuqKRLvQ89ixY3j44YexcOFCPPHEEwCAmpoaTJ48Ge7u7li1atVNj33qqaeQkZGBHTt2QKlUAqifdR8zZgwCAgLw/ffft7oeXuhJZLk4ViyLwSBg/5kSbEjNRsElDTycbTB5aACGhHlAJhV1rqfb41ghMo8lXugp2k/PzZs3Q6FQ4OGHHzZus7KywrRp03Dw4EGUlJTc9Niqqio4ODgYAzkAKJVKODg4wMrKql3rJiLq7qRSCWL6emDxk9H484P9oJRLseLX03j9yzTsPloAnd4gdolERJ2OaKH89OnT6NmzJ1Qqlcn2iIgICIJwy5sPRUdHIzMzE5988glyc3ORm5uLTz75BNnZ2Zg3b157l05ERACkEgkG9XHH3+cOxgvx4VBZK/DNpjNY+J+92HkoD3U6hnMiInOJdqFnaWkpPDw8mm13c3MDgFvOlD/77LPIzc3FsmXLsHTpUgCAjY0NlixZguHDh99RPTf7KKG9ubnZifK8RJ0Nx4pli3O3x9ihPXHwTAl+2JaB77aexa9puYiPDca4IYGwUsjELrHb4FghMo+ljRXRQnl1dTUUCkWz7Y3tJzU1NTc9VqlUIjAwEOPHj8fYsWOh1+uRkJCAv/zlL/jmm28QERHR6nrYU05kuThWOo8AVxu8MqM/Tudcwfo/svHVzyfww7azGB/tj1FR3rBWciXe9sSxQmQeS+wpF+2no7W1Nerq6pptbwzjt+oNf/fdd3H8+HEkJiZC2nBR0YQJEzB58mT84x//wNq1a9unaCIiui2JRIK+gc7oG+iMjNwr2JCajYSd57AxLQfjov0QO8AXPawYzomImhKtp9zNza3FFpXS0lIAgLu7e4vH1dbWIjExEaNGjTIGcgBQKBS45557cPz4ceh0uvYpmoiIWiXE3wkvz4jC67MHoqeXPdbtOo9Xl6Zi/Z4L0FY3n5ghIuquRAvlffr0wYULF6DRaEy2Hz161Ph4S65evQqdTge9Xt/sMZ1OB51OB5FWeSQiopsI9nHAgkci8dbjg9Db1xE/77mAV5amIml3FqquMZwTEYkWysePH4+6ujqTm/3U1tYiKSkJAwYMMF4EWlBQgKysLOM+Li4usLe3x7Zt20zaXzQaDXbu3Am1Wt1irzoREYmvp5c9XpwWgb/PHYywQGckp+bglaWp+HHnOVRoasUuj4hINP+/vfsOiOrM1wf+TGGGNvRhBumCFAek2BiwK0rsm2hMLKlr1kRNjDdts3fvzRZ380vcaGKMSXTvrhqzSSwEMfYWoww2jMoAElAQAjMgSkeKzO8PlISAERQ4Azyf/zhzyhfkyDPvfM/7CtbUFxYWhri4OKxcuRLFxcXw8vJCfHw8CgoK8Pe//715v9dffx2nTp3CpUuXAAASiQTPPPMMVq9ejTlz5mD69OlobGzEtm3bYDAY8Prrrwv1LRERUTt5qRR44Teh+LG4Ert0udh78ioOnc3HmAh3xA33goMt15wgor5FsBU9gaaHOlevXo3ExESUlZUhMDAQy5cvR3R0dPM+CxYsaBHK70hMTMSmTZuQk5ODuro6BAYGYuHChYiNjb2vWjj7CpH54r3S+xWWVOEbXS6S9UaIxSKMCnPD5ChvONlZCl1aj8J7hah9zHH2FUFDuTlhKCcyX7xX+o6iG9X4RpeLpFQDAGDEoKZwrnSwEriynoH3ClH7mGMo55xURERkNlwdrfH05GBMi/HBnuSr+O5CAb47X4joEDWmRHtD5WgtdIlERF2CoZyIiMyOi70VFkwKxNRoH+xJzsW35wtwIrUQwweqMFXrg34uNkKXSETUqRjKiYjIbDkq5JgbG4ApWm/sO5WHw+fycVJvxJAgV0yL9oGHa9sfAxMR9TQM5UREZPbsbeV4dJw/4qK8cOB0Hg6ezcfpjCJEBigxLdoH3mqF0CUSET0QhnIiIuox7KxleGS0HyYN88LBM3k4cCYfKZnFGOTnjGkxPvDrZy90iURE94Wzr9zG2VeIzBfvFbqb6psNOHQ2D/tP56HqZgM0vk6YFu2DAE8HoUsTBO8Vovbh7CtERESdyNpSimkxvpgwxBNHz/2Ivaeu4u0tKQjycsC0GF8EeTlAJBIJXSYR0T0xlBMRUY9nJZfioShvjIv0wLff/4g9J6/i3f+cg7+HPabH+EDj48RwTkRmjaGciIh6DblMgonDvDAmwh3fXSjE7uRcvPflefi62WF6jA8G+TkznBORWWIoJyKiXkdmIcH4wR4YFdYPJ1ILsVuXi/e3XYC3SoGp0T6ICHCBmOGciMwIQzkREfVaFlIxxoS7Y0SoG3R6A77R5WJt/EV4KG0wNdoHQwJdIRYznBOR8BjKiYio15NKxBg5qB+iQ9Q4lVaEXbocfJygh5vzFUyN9sGwYFdIxGKhyySiPoyhnIiI+gyJWAxtiBrDB6pw5lIREpNysD4xDQnHr2CK1htajRpSCcM5EXU/hnIiIupzxGIRhgWrMCTIFecyryEx6Qr+tTsDiSdyMFnrjZgQN1hIGc6JqPswlBMRUZ8lFokwOFCJyAAXnM8uQeKJHGzae6kpnEd5Y1SYGyykEqHLJKI+gKGciIj6PJFIhHB/F4T5OUOfcx07T+Rgy4FM7NLl4KFhXhgd4Q65BcM5EXUdhnIiIqLbRCIRQnydofFxQsbVUiSeuIIvDmdhd3IuJg3zwthId1jK+KeTiDof/2chIiL6BZFIhGBvRwR7OyIzrxSJSTnYejQbu5NzMXGYF8ZHesDakn9Ciajz8H8UIiKiXxHg6YD/mhOO7IIyJJ7IQfyxy9h38iomDPHAhCGesLWyELpEIuoFGMqJiIjawa+fPZbNDkOOoRyJJ3Kw80QO9p/Ow/jBHpg41BMKa5nQJRJRD8ZQTkRE1AE+ajssfWQQ8ooqsSspB7t1uThwJg/jIjwwaZgn7G3lQpdIRD0QQzkREdF98HS1xfMzQ1BwrQq7dDnYd/oqDqXkY3RYPzwU5Q1HBcM5EbUfQzkREdED6Odig+emaTAjxhff6HJxOOVHHP3+R4wc1A8PRXnBxd5K6BKJqAdgKCciIuoEKidrPDMlGNNifLA7ORfHzhfg2PkCxISqMVnrA1cHhnMiujuGciIiok6kdLDCk3FBmBZ9J5wX4vgFA7QaFaZE+0DtZC10iURkhhjKiYiIuoCTnSXmTwzEFK0P9p26iqPnfkSS3oBhwSpM1XrDXWkrdIlEZEYYyomIiLqQo0KOx8YPwENR3th/6ioOp/yIU2lGDA5UYmq0D7xUCqFLJCIzwFBORETUDextZJg91h9xw71w4EweDp3Nx5lLxQj3d8G0GB/4utkJXSIRCUhkMplMQhdhDkpKKtHY2L0/CqVSgeLiim69JlFPxHuFeqOqm/U4eCYfB07nobq2AaH9nTEtxgf+7vb3fU7eK0TtI9S9IhaL4OzcdusaQ/ltDOVE5ov3CvVmNbUNOJySj32n8lBZU4+BPo6YFu2DQC/HDp+L9wpR+5hjKGf7ChERkYCs5FJM0fpg/GAPHD1XgL2nruL/fX4OAZ4OmB7jg2BvR4hEIqHLJKIuxlBORERkBixlUsQN98K4SHd8e74Ae5JzsfKL7+HnbofpMb4I8XViOCfqxRjKiYiIzIjMQoLYIZ4YE94Pxy8U4pvkXKz66jx81ApMi/FBuL8LwzlRL8RQTkREZIYspBKMjfTAyLB+SEo1YFdSDtZsvwgvV1tMjfZBZKASYoZzol6DoZyIiMiMSSVijArrh+gQNU6mGbErKQcffZ0KdxcbTI32wdAgV5xMN2LHt9m4Xl4LJzs5Hh7tB61GLXTpRNQBnH3lNs6+QmS+eK8Q/aSx0YRTGUbsSspFwbUq2NlYoOpmA27d+ulvmEwqxpMPBTGYE92FOc6+Iu7mWoiIiOgBiMUiRA1U48/PDsMLM0NQVdMykANAXUMjdnybLVCFRHQ/GMqJiIh6ILFIhCFBrrh1l095S8pr0XCrsZurIqL7xVBORETUgznbye/62strjmPzvkvI+rEM7FYlMm980JOIiKgHe3i0HzbuyUBdw0+j4jKpGGMj3XGjohbHLxbiyLkfoXSwhFajhlajhsrJWsCKiagtDOVEREQ92J2HOe82+0pNbQPOXiqGTm9A4okc7DyRg/797KDVqDE02BV21jIhyyei2zj7ym2cfYXIfPFeIWqfe90rNypqcTLNiKRUA/KLKyERixDi6wRtiBrh/i6QWUi6sVoi4Zjj7CscKSciIuojHBVyxA33QtxwL+QVVSJZb0BymhHnE/SwlEkwJNAVWo0KgV6OEIu5MBFRd2IoJyIi6oM8XW3h6eqPR0b74dLVG9DpjThzqQjHLxbCUSFH1EAVtBo1PFzbHtUjos7F9pXb2L5CZL54rxC1z4PeK7X1t3A+6xp0qQakXrmOW40meLraQqtRY/hAFRwVd5/phagnYfsKERERmS25hQTDglUYFqxCeXUdTqcXQac34KsjWdh6JAvBPo7QatSIDFDCSs4IQdSZOFJ+G0fKicwX7xWi9umqe8V4vRo6vQE6vQHFpTchk4oRPsAF0SFqDPRxglTCZU+oZ+FIOREREfU4KidrzBzZHzNG+CK7oBy6VANOpRtxKr0ICmsLDAtWITpEDR+1AiIRHxAluh8M5URERNQuIpEI/u728He3x+MTBuDi5RLoUg349vsCHDqbD5WTNbSapgdElQ5WQpdL1KMwlBMREVGHSSViRAxQImKAEtU363HmUjF0qQZ8/d0VfP3dFfh72DctUBTkClsrC6HLJTJ77Cm/jT3lROaL9wpR+5jDvVJSdhPJaQbo9EYUXKuCRCzCID9naDVqhPk7w0LKBYpIeOwpJyIiol7N2d4SU7Q+mBzljavGSuj0BpxMM+LcD9dgLZdiSFDTAkUDPB0gZv85UTNBQ3ldXR3ef/99JCQkoLy8HEFBQXj55Zeh1WrbdXxiYiI2btyIrKwsyGQyBAQE4LXXXsOgQYO6uHIiIiL6NSKRCN5qBbzVCswe64f03BvQpRpxMs2IY+cL4Gxniajb/ef9XGyELpdIcIKG8jfeeAP79+/HE088AW9vb8THx2PhwoXYvHkzIiIifvXYVatWYcOGDZg+fTrmzJmD6upqZGRkoLi4uJuqJyIiovaQiMUI8XVGiK8zautuIeWHYuj0BuxOzsU3ulx4qxTQhqgxPNgV9rZcoIj6JsF6yi9cuIDZs2fj97//PZ566ikAQG1tLaZOnQpXV1ds2bLlrsempKRg7ty5WLNmDWJjYzulHvaUE5kv3itE7dPT7pWyylqcvL1AUa6hAiIRoPFxal6gSC5j/zl1DfaU/8zevXthYWGB2bNnN2+Ty+WYNWsWVq1ahaKiIri6urZ57KZNmxAaGorY2Fg0NjaipqYGNjb86IuIiKgnsbeVY+JQT0wc6omCa1XQ6Q1I1huxflca5BYSRAa4QBuiRrC3IyRiLlBEvZtgoTw9PR2+vr6twvSgQYNgMpmQnp5+11Cu0+kwZcoUvPfee9i8eTOqq6vh7u6OZcuWYfr06d1RPhEREXWifi42eGS0H34zqj+y8suQlGrA6Ywi6PRG2NvIMHxgU/+5l8qWCxRRryRYKC8uLoZKpWq1XalUAgCKioraPK6srAylpaX45ptvIJFI8Morr8DBwQFbtmzBq6++Cisrq05raSEiIqLuJRaJEODpgABPB8yLHYAL2SVISjXg0Nl87D+dh34uNtBqVIgaqIazvaXQ5RJ1GsFC+c2bN2Fh0XoxAbm86QGP2traNo+rrq4GAJSWluKrr75CWFgYACA2NhaxsbFYu3btfYXyu/X3dDWlUiHIdYl6Gt4rRO3T2+6Vfm4OiBvhh4rqOhw/X4CjZ/Ow/dvL2P7tZYT4OWNMpCdiwvpxgSLqMHO7VwQL5ZaWlqivr2+1/U4YvxPOf+nOdg8Pj+ZADgAymQyTJk3Cpk2bUFVV1eEecz7oSWS+eK8QtU9vv1eG+DtjiL8zikprcFJvQJLeiA+3fo+Pd1xAuH/TAkWhfs6QSth/Tr+OD3r+jFKpbLNF5c6UhnfrJ3dwcIBMJoOLi0ur11xcXGAymVBZWdnpD37W19ehoqIUDQ11aGy81SnnLCoSo7GxsVPOReZBIpHC1tYBVlZ88JiIqKu4OlhhWowvpkb7IMdQAV2qASfTjThzqRg2llIMC27qP/dzt2P/OfUYgoXyoKAgbN68udWo9vnz55tfb4tYLEZwcDCMRmOr1wwGAyQSCezt7Tu11pqaKlRU3ICtrT3kcieIxZJOucmlUjEaGhjKewuTyYT6+jqUlja9sWQwJyLqWiKRCL5udvB1s8Oj4/yRlnMdOr0RJy4W4si5H6F0sIRWo0aURg21k7XQ5RL9KsE+34mLi0N9fT22bt3avK2urg47duxAZGRk80OgBQUFyM7ObnVsYWEhTpw40bytsrISe/bsQUREBCwtO/fBj8rKMjg4uMDaWgGJRMp33dQmkUgEmUwOBwclKitLhS6HiKhPkUrEGOTngt9N12DV0hF4dkowlA5WSDyRgzc/TcZfNp7BobP5KK+uE7pUojYJtngQALz00ks4dOgQnnzySXh5eSE+Ph6pqanYuHEjBg8eDABYsGABTp06hUuXLjUfV1NTg4cffhhGoxFPPfUU7OzssH37dly5cqXFsR3xaz3lBkMuVCqvTg/jHCnvnUwmE4zGq1CrvYUupdfo7X2yRJ2F90prNypqcTLNCJ3egLyiSohFIoT0b1qgKHyAC+QWXKCoL2JP+S+88847WL16NRISElBWVobAwEB8+umn9wzVVlZW2LRpE9555x189tlnuHnzJjQaDf71r3/dVyBvD46OU3vxd4WIyHw4KuSIG+6FuOFeyC+qhC6taYGiC9l6WMokGByohFajRpCXI8Ri/v9NwhF0pNyc3GukvCtGPTlS3nt11e9MX8XRP6L24b3SPo0mEy5dLYVOb8DZS0Woqb0FR4W8eYEiT1dhpkmm7sORcupzlix5DgDw4YefduuxREREdyMWiRDs7Yhgb0fMjw3A91nXkKw34sDpPOw9eRUeSltoQ1QYHqyCkx0XKKLuwVDeR40YMaRd+23duhNubv26uBoiIiJhyCwkGBaswrBgFcqr63A6vQjJegO2HsnGtiPZCPJ2hFajxuBAJazkjE3Uddi+cltfa1/Zt293i6+/+uo/MBoLsXTp8hbbR40aCysrq/u+zp0FotpavbUrjxUa21c6Fz+SJ2of3iudx3i9Gjp9U/95UWkNLKRiRAxwgVajhsbXiQsU9XBsXyGzMWnS5BZfHz16CGVlpa22/9LNmzc7NOXkgwTqnhjGiYiod1A5WWPmyP6YMcIX2QXl0OkNOJ1ehFPpRVBYWzQvUOTrpuAD/tQpGMrprpYseQ6VlZV47bU3sWbNKly6lIF5857As8/+Dt99dxQ7d8YjM/MSysvLoFS6YvLkaViw4GlIJJIW5wB+6gtPSTmDF19chBUr3sGVK5fx9dfbUV5ehtDQMLz66pvw8PDslGMBYPv2r/DFF1tQUnINfn5+WLLkZaxfv67FOYmIiH6NSCSCv7s9/N3t8fj4Abh4uQQ6vRHffl+AQ2fzoXKyhlajQpRGDVeH+/9kmYihXCA6vQE7jl1GSdlNONvJ8fBoP2g1aqHLaqW09AZee+1lTJwYh7i4KVCpmmrcvXsXrKysMWfOPFhbW+Hs2TPYsOFjVFVVYfHil+553o0b/wmxWIK5c59ARUU5/vOfzfjTn/4b69dv7JRj4+O3YdWqdxAeHok5cx5HYWEhfv/7V6BQKKBUut7/D4SIiPosqUSMiAFKRAxQovpmA85eKoJOb8DX313B199dgb+7PbQhagwNcoWtFT/tpY5hKBeATm/Axj0ZqLvdT15SXouNezIAwOyC+bVrxXjjjT9i6tQZLba/9dZfIZf/1MYyc+YsvPvu3xAfvxULFz4PmUz2q+dtaGjA//3fRkilTb+Cdnb2eP/9lbh8OQv9+/s/0LH19fXYsGEdNJpQrF79UfN+/v4DsGLFWwzlRET0wKwtpRgZ1g8jw/qhpOwmTqYboUs1YPO+S/j8QCYG+TlDq1EjzN8ZFlIuUET3xlD+AE5cLMTxC4UdPi67oAwNt1o+VFrX0Ih/7U7Hse8LOny+EYPcEBPq1uHj2sPS0hJxcVNabf95IK+urkJdXT3CwiKQkLADubk5GDAg4FfPO2XK9OawDABhYeEAgIKCH+8Zyu91bEZGGsrKyvDCC79psV9sbBw++OC9Xz03ERFRRznbW2JylDceGu6FvKLKpgdE04w498M1WMmlGBrUtEDRAE8HiNl/TnfBUC6AXwbye20XklLp2iLY3nH5cjbWr1+HlJTTqKqqavFaVVXlPc97pw3mDoXCDgBQUXHvJ6HvdazB0PRG6Zc95lKpFG5uXfPmhYiISCQSwUulgJdKgdlj/JGeewM6vQEn04pw7HwhnO3kiNKoEaVRw93FRuhyycwwlD+AmND7G6F+9aMTKCmvbbXd2U6O1+dFdkZpnebnI+J3VFRUYOnS52BtbYtnn10Ed3cPyGQyZGZmYN26NWhsvPc0j2Jx2x/ltWeGzgc5loiIqDuIxSJofJ2g8XXCgom3cO6HYuj0RuxJvopvdLnwVimg1agwbKAKDrZyocslM8BQLoCHR/u16CkHAJlUjIdH+wlYVfudO3cWZWVlWLHiXYSH//QmorCw4603XUGtbnqjlJ+fh7CwiObtDQ0NKCwshJ/fr7fHEBERdSa5TNI8Ql5WVYdTaUbo9AZ8cTgLXx7JwkAfJ0Rr1IgIcIGljNGsr+K/vADuPMzZE2ZfaYtY3LRgws9Hpuvr6xEfv1WokloIChoIe3t77NwZj0mTJje33xw4sBcVFeUCV0dERH2ZvY0MsUM9ETvUE4UlVdDpDdClGrF+VxpkFmJEBigRrVEj2McREjEXKOpLGMoFotWoMTKsn2Arej6I0NBBUCjssGLFW5g1aw5EIhH27dsNc+kesbCwwDPPPIdVq97FsmUvYOzY8SgsLMSePYlwd/fgIg9ERGQW3Jxt8PAoP8wc2R9Z+WXNCxQl642ws5FheLAK0SFqeKls+berD2Aopw6zt3fAO++swocfrsb69eugUNhh4sSHMGTIMCxfvkTo8gAAjzwyByaTCV98sQVr174PP78BePvt97B69UrIZOzdIyIi8yEWiRDg6YAATwfMnRCAC9klSNYbcORcPg6cyYObszW0GjWiNCq42HOBot5KZOLTcQCAkpJKNDa2/aMwGHKhVnt3+jWlUnGPHCnvqRobGzF1aixGjx6L11//7y69Vlf9zvRVSqUCxcX3npmHqK/jvdK7VNbU48ylIiSnGpCZXwYACPB0gFajwtAgV1hbcoGi+yXUvSIWi+DsbNvmaxwpp16ptrYWcnnLEfG9e79BeXkZIiIGC1QVERFR+9laWWBMuDvGhLujuLQGyWlNCxRt3HsJWw5kIszfBVqNGoP8nCGVsP+8p2Mop17pwoXvsW7dGowZMw52dvbIzMzAN9/sRP/+fhg7doLQ5REREXWI0sEK06J9MFXrjRxDBXR6A06lGXH2UjFsLKUYGqyCVqOCv7s9+897KIZy6pX69XOHi4sS27Z9ifLyMtjZ2SMubgoWLVoCCwt+3EdERD2TSCSCr5sdfN3sMGecP9JybkCXakDSxUIcPfcjXOwtodWooQ1RQ+1kLXS51AHsKb+NPeXUmdhT3rnYJ0vUPrxX+q6a2gakZBYjWW9AWu4NmEyAr5td0wJFwSrY2ciELtGssKeciIiIiDqdlVzavNL4jYpanEwzIllvwOcHf8AXh7IQ0t8JWo0a4QNcILdoe2VsEhZDOREREVEv4qiQI264F+KGeyG/uBI6vQHJeiMuZOshl0kwJEAJbYgaQV6OEIvZf24uGMqJiIiIeikPpS1mj/HHI6P9kHm1FDq9AWcuFeFEqgEOtjJEDWzqP/d0bbulgroPQzkRERFRLycWiRDk7Yggb0fMiw3A+ewS6FINOHAmD3tPXYWH0gZajRrDB6rgZGcpdLl9EkM5ERERUR8is5BgaJArhga5oqK6DqcziqDTG7D1aDa2Hc1GkLcjojQqDAl0hZWcUbG78CdNRERE1EcprGUYF+mBcZEeMN6oRrLeCJ3egH/tzsBn+zMRMcAFURo1QnyduEBRF2MoJyIiIiKoHK0xY4Qvpsf44HJBedMCRelFOJVeBFsrCwwPViEqRIX+bnZcoKgLMJQTERERUTORSAQ/d3v4udvjsfEDkHrlOnSpBhy7UIBDKflQOVpBq1EjSqOCqyMXKOos/ByCOsXu3YkYMWIICgsLmrfNmjUNK1a8dV/HPqiUlDMYMWIIUlLOdNo5iYiI+hqpRIxwfxc8PzMEq5aMwNOTg+CokCPh+BW88UkyVmw+gyMp+aisqRe61B6PI+V91GuvvYyUlNNITDwAKyurNvdZvnwJ9PqL2LlzP+RyeTdX2D4HD+7D9eslePTRuUKXQkRE1KtZW0oxclA/jBzUD9fLb+JkmhFJegM278/E5wd/QGh/Z0SHqBHm7wwLKRco6iiG8j4qNnYSkpK+w/Hj3yI2Nq7V6zduXMfZs6cxceJD9x3IP/98O8Tirv0w5tCh/fjhh8xWoTw8PBKHDp2AhYVFl16fiIioL3Kys8RDUd6IG+6FvKJKJOuNSE4z4Pusa7CSSzEkUInoEDUGeDpAzP7zdmEo76NGjhwDKytrHDy4r81QfvjwQdy6dQsTJ7Z+rb1kMtmDlPhAxGKx2Y4h0WCcAAAUYElEQVTuExER9RYikQheKgW8VArMGuOH9Ks3kJxqwKmMInx3oRBOdvLmBYrcXWyELtesMZT3UZaWlhg5cjSOHDmI8vJy2NnZtXj94MF9cHZ2hqenN1aufBtnz56C0WiEpaUlIiOHYPHil+Dm1u9XrzFr1jRERAzGH/7wVvO2y5ezsXr1u0hNvQh7e3vMmPEwXFyUrY797ruj2LkzHpmZl1BeXgal0hWTJ0/DggVPQyJp+khsyZLn8P33KQCAESOGAADUajds25aIlJQzePHFRfjgg48RGTmk+byHDu3HZ5/9G7m5ObC2tkFMzEg8//yLcHBwaN5nyZLnUFlZif/5nz/jvffeQXq6HgqFHWbPfgzz5j3ZsR80ERFRHyEWi6DxcYLGxwnz62/h3A/FSNYbsffkVexOzoWXyrZ5gSIHWw6c/RJDuUBOGVKQeHkvrt8shaPcAdP94jBMHdmtNcTGxmH//j04evQQpk//TfN2g6EQqakXMGvWY0hP1yM19QImTJgEpdIVhYUF+Prr7Vi69Hf47LOtsLRs/6pfJSXX8OKLi9DY2Ij585+EpaUVdu6Mb3NEe/fuXbCyssacOfNgbW2Fs2fPYMOGj1FVVYXFi18CADz55DOoqamB0ViIpUuXAwCsrO7+FPju3Yn429/+BI0mFM8//yKKiozYvv1LpKfrsX79phZ1lJeX4b/+60WMHTse48dPxJEjB7Fu3Rr07+8PrTam3d8zERFRXyS3kCBqoBpRA9Uor6rDyXQjkvUGfHk4C18dycJAHydoNSpEBihhKWMcBRjKBXHKkILPM7ajvrHpSeUbtaX4PGM7AHRrMB86dDgcHBxx8OC+FqH84MF9MJlMiI2dBD8/f4wdO6HFcTExo7Bo0dM4evQQ4uKmtPt6W7ZsRFlZKTZs2IzAwCAAwEMPTcXjj/+m1b5vvfVXyOU/Bf6ZM2fh3Xf/hvj4rVi48HnIZDIMHRqFHTu2oqysFJMmTf7Vazc0NGDdujXw9w/AmjWfNLfWBAYG4a23/oDExHjMmvVY8/5FRUb87//+tbm1Z+rUGZg1ayq++SaBoZyIiKgD7GxkiB3iidghnigsqYJO3xTQN+xKh8ziEiIDlNBq1Bjo4whJFz+LZs4Yyh/AycKz0BWe7vBxV8quosHU0GJbfWM9tqRvQ1LBqQ6fT+s2FMPdBnf4OKlUinHjJuDrr7fj2rVrcHFxAQAcPLgfHh6eGDgwpMX+DQ0NqKqqhIeHJ2xtFcjMzOhQKNfpTiA0NKw5kAOAo6MjYmMfQnz81hb7/jyQV1dXoa6uHmFhEUhI2IHc3BwMGBDQoe81IyMNN25cbw70d4wbF4u1a99HUtKJFqHc1tYWEyZMav7awsICwcEaFBT82KHrEhER0U/cnG3w8Kj++M1IX2T9WAad3ojT6UYk642ws5FheLAK2hAVvFWKPrdAEUO5AH4ZyO+1vSvFxsZhx46tOHx4Px59dC5ycq4gKysTTz+9EABQW3sTmzf/G7t3J6K4uAgmk6n52MrKyg5dy2g0IDQ0rNV2Ly/vVtsuX87G+vXrkJJyGlVVVS1eq6rq2HWBppactq4lFovh4eEJo7GwxXZXV1Wr/wwUCjtkZ2d1+NpERETUkkgkwgAPBwzwcMDj4wfg4uUS6FINOHIuHwfO5MHN2RpRGjW0A1VwcWh76ubehqH8AQx3G3xfI9T/feJvuFFb2mq7o9wByyIXdUZp7RYaGgY3N3ccOLAXjz46FwcO7AWA5raNVavexe7diZg9+3GEhITC1tYWgAhvvfVmi4DemSoqKrB06XOwtrbFs88ugru7B2QyGTIzM7Bu3Ro0NjZ2yXV/Tixue37VrvqeiYiI+ioLqRiRAUpEBihRdbMeZzKKoEs1IP7YZcQfu4wAD3tEhagxNMgVNpa9d6pjhnIBTPeLa9FTDgAWYgtM97v/6QcfxIQJE7F587+Qn5+HQ4f2IzAwuHlE+U7f+NKlLzfvX1tb2+FRcgBQqdTIz89rtf3q1dwWX587dxZlZWVYseJdhIf/1GPf9oqf7ftoS612a77Wz89pMpmQn58HX1+/dp2HiIiIuo6NpQVGh7tjdLg7rpXWIDnNCJ3egE17L+HzA5kI83NBlEaNQX7OsJD2rv7z3vXd9BDD1JGYG/QInCybpuFzlDtgbtAj3T77yh0TJz4EAPjww1XIz89rMTd5WyPG27d/iVu3bnX4OlptDC5ePI9LlzKat924cQMHDuxpsd+dBYd+PipdX1/fqu8cAKysrNr1BiEoaCAcHZ3w9dfbUF//05uhI0cOobi4CNHRfHiTiIjInLg4WGFqtA/++tvh+J+nhmBshAd++LEMa+MvYvmHx7FpbwYy80p7zafYHCkXyDB1JKI9hqChoetbMe7F17c//P0DcPz4MYjFYowf/9MDjtHRI7Bv327Y2NjCx8cXev1FnDlzCvb29h2+zty5T2Lfvt1YvnwxZs16DHK5JXbujIdK5YbKyh+a9wsNHQSFwg4rVryFWbPmQCQSYd++3WjrngsMDML+/XuwZs17CAoaCCsra4wYMarVflKpFM8/vxR/+9ufsHTp7zBhwkQUFRmxbduX6N/fD9OmtZ4BhoiIiIQnEongo7aDj9oOj47zQ1rODej0BiTpDTj6fQFc7C2b+s81Krg599wFihjKCQAwcWIcsrIyERExuHkWFgB46aVXIBaLceDAHtTW1iE0NAyrV6/F8uVLO3wNFxcXfPDBJ1i16h1s3vzvFosHvf32X5r3s7d3wDvvrMKHH67G+vXroFDYYeLEhzBkyDAsX76kxTlnzHgEmZkZ2L17F7788nOo1W5thnIAmDx5GmQyGbZs2Yi1a9+HjY0NYmPjsGjRUq7+SURE1ANIxGKE9ndGaH9n3KxrQEpmMXR6I77R5WBXUg583RSI0qgxPFgFOxvhVha/HyJTbxnzf0AlJZVobGz7R2Ew5EKtbj1DyIOSSsVmMVJOna+rfmf6KqVSgeLiCqHLIDJ7vFeoryqtrMXJ2/3nV42VEItECOnvhCiNChEDlJBbNLXj6vQG7Pg2G9fLa+FkJ8fDo/2g1ai7rU6xWARnZ9s2X+NIORERERH1aA62ckwa5oVJw7zwY3Fl0wJFaQZ8urMEcpkEQwKUsLeV4eCZfNTdHhAtKa/Fxj1Nz7l1ZzC/G4ZyIiIiIuo13JW2mDXGFg+P7o8f8kqh0xtwOqMYNbWt14Opa2jEjm+zzSKUc/YVIiIiIup1xCIRAr0c8dRDwVi99O6zrJWU13ZjVXfHUE5EREREvZqFVAJnu7Yndbjb9u7GUE5EREREvd7Do/0g+8WCQzKpGA+PNo8FBNlTTkRERES93p2+cSFnX/k1DOXtZDKZIBK1b0l36ts4yygREZF50mrU0GrUZjl9KNtX2kEisUB9vXk8BEDmr76+DhIJ3+8SERFR+zGUt4OtrT1KS6+hqqoCt241cCSU2mQymVBXV4vS0mLY2joIXQ4RERH1IBzOawcrKxtIpRaorCxFVVUZGhtvdcp5xWIxGhu5omdvIpFIoVA4wsrKRuhSiIiIqAdhKG8nCwsZHB1dO/Wc5tjPRERERETdj+0rREREREQCYygnIiIiIhIYQzkRERERkcAYyomIiIiIBMZQTkREREQkMM6+cptYLMxqnUJdl6in4b1C1D68V4jaR4h75deuKTJxJRwiIiIiIkGxfYWIiIiISGAM5UREREREAmMoJyIiIiISGEM5EREREZHAGMqJiIiIiATGUE5EREREJDCGciIiIiIigTGUExEREREJjKGciIiIiEhgDOVERERERAKTCl1AX1NUVIRNmzbh/PnzSE1NRXV1NTZt2oThw4cLXRqR2bhw4QLi4+Nx8uRJFBQUwMHBAREREVi2bBm8vb2FLo/IbFy8eBEff/wx0tLSUFJSAoVCgaCgICxevBiRkZFCl0dk1tavX4+VK1ciKCgICQkJQpfDUN7drly5gvXr18Pb2xuBgYE4d+6c0CURmZ0NGzYgJSUFcXFxCAwMRHFxMbZs2YKZM2di27Zt8PPzE7pEIrOQl5eHW7duYfbs2VAqlaioqEBiYiLmz5+P9evXIyYmRugSicxScXEx1q1bB2tra6FLaSYymUwmoYvoSyorK1FfXw9HR0ccPHgQixcv5kg50S+kpKQgJCQEMpmseVtOTg6mTZuGKVOm4O233xawOiLzVlNTgwkTJiAkJASffPKJ0OUQmaU33ngDBQUFMJlMKC8vN4uRcvaUdzNbW1s4OjoKXQaRWYuMjGwRyAHAx8cHAwYMQHZ2tkBVEfUMVlZWcHJyQnl5udClEJmlCxcuYOfOnfj9738vdCktMJQTUY9gMplw7do1vqklakNlZSWuX7+Oy5cv47333kNmZia0Wq3QZRGZHZPJhL/85S+YOXMmgoODhS6nBfaUE1GPsHPnThiNRrz88stCl0Jkdt58803s27cPAGBhYYHHHnsMixYtErgqIvPz9ddfIysrC2vXrhW6lFYYyonI7GVnZ+PPf/4zBg8ejBkzZghdDpHZWbx4MebMmQODwYCEhATU1dWhvr6+VRsYUV9WWVmJf/zjH3juuefg6uoqdDmtsH2FiMxacXExfve738He3h7vv/8+xGL+t0X0S4GBgYiJicEjjzyCf/7zn9Dr9WbXL0sktHXr1sHCwgJPP/200KW0iX/diMhsVVRUYOHChaioqMCGDRugVCqFLonI7FlYWGD8+PHYv38/bt68KXQ5RGahqKgIGzduxNy5c3Ht2jXk5+cjPz8ftbW1qK+vR35+PsrKygStke0rRGSWamtrsWjRIuTk5ODf//43+vfvL3RJRD3GzZs3YTKZUFVVBUtLS6HLIRJcSUkJ6uvrsXLlSqxcubLV6+PHj8fChQvxyiuvCFBdE4ZyIjI7t27dwrJly/D999/jo48+Qnh4uNAlEZml69evw8nJqcW2yspK7Nu3D25ubnB2dhaoMiLz4uHh0ebDnatXr0Z1dTXefPNN+Pj4dH9hP8NQLoCPPvoIAJrnW05ISMDZs2dhZ2eH+fPnC1kakVl4++23cfjwYYwdOxalpaUtFnWwsbHBhAkTBKyOyHwsW7YMcrkcERERUCqVKCwsxI4dO2AwGPDee+8JXR6R2VAoFG3+7di4cSMkEolZ/F3hip4CCAwMbHO7u7s7Dh8+3M3VEJmfBQsW4NSpU22+xvuE6Cfbtm1DQkICsrKyUF5eDoVCgfDwcDzzzDMYNmyY0OURmb0FCxaYzYqeDOVERERERALj7CtERERERAJjKCciIiIiEhhDORERERGRwBjKiYiIiIgExlBORERERCQwhnIiIiIiIoExlBMRERERCYyhnIiIBLNgwQKMGzdO6DKIiAQnFboAIiLqXCdPnsQTTzxx19clEgnS0tK6sSIiIroXhnIiol5q6tSpGDVqVKvtYjE/JCUiMjcM5UREvdTAgQMxY8YMocsgIqJ24HAJEVEflZ+fj8DAQKxZswa7du3CtGnTEBoaijFjxmDNmjVoaGhodUxGRgYWL16M4cOHIzQ0FJMnT8b69etx69atVvsWFxfjr3/9K8aPH4+QkBBotVo8/fTTOHHiRKt9jUYjli9fjqFDhyIsLAzPPvssrly50iXfNxGROeJIORFRL1VTU4Pr16+32i6TyWBra9v89eHDh5GXl4d58+bBxcUFhw8fxocffoiCggL8/e9/b97v4sWLWLBgAaRSafO+R44cwcqVK5GRkYF//OMfzfvm5+fj8ccfR0lJCWbMmIGQkBDU1NTg/PnzSEpKQkxMTPO+1dXVmD9/PsLCwvDyyy8jPz8fmzZtwgsvvIBdu3ZBIpF00U+IiMh8MJQTEfVSa9aswZo1a1ptHzNmDD755JPmrzMyMrBt2zZoNBoAwPz587FkyRLs2LEDc+bMQXh4OABgxYoVqKurwxdffIGgoKDmfZctW4Zdu3Zh1qxZ0Gq1AIA//elPKCoqwoYNGzBy5MgW129sbGzx9Y0bN/Dss89i4cKFzducnJzw7rvvIikpqdXxRES9EUM5EVEvNWfOHMTFxbXa7uTk1OLr6Ojo5kAOACKRCL/97W9x8OBBHDhwAOHh4SgpKcG5c+cQGxvbHMjv7Pv8889j7969OHDgALRaLUpLS/Hdd99h5MiRbQbqXz5oKhaLW80WExUVBQDIzc1lKCeiPoGhnIiol/L29kZ0dPQ99/Pz82u1zd/fHwCQl5cHoKkd5efbf65///4Qi8XN+169ehUmkwkDBw5sV52urq6Qy+Uttjk4OAAASktL23UOIqKejg96EhGRoH6tZ9xkMnVjJUREwmEoJyLq47Kzs1tty8rKAgB4enoCADw8PFps/7nLly+jsbGxeV8vLy+IRCKkp6d3VclERL0OQzkRUR+XlJQEvV7f/LXJZMKGDRsAABMmTAAAODs7IyIiAkeOHEFmZmaLfT/99FMAQGxsLICm1pNRo0bh2LFjSEpKanU9jn4TEbXGnnIiol4qLS0NCQkJbb52J2wDQFBQEJ588knMmzcPSqUShw4dQlJSEmbMmIGIiIjm/f7whz9gwYIFmDdvHubOnQulUokjR47g+PHjmDp1avPMKwDwxz/+EWlpaVi4cCFmzpwJjUaD2tpanD9/Hu7u7nj11Ve77hsnIuqBGMqJiHqpXbt2YdeuXW2+tn///uZe7nHjxsHX1xeffPIJrly5AmdnZ7zwwgt44YUXWhwTGhqKL774Ah988AH+85//oLq6Gp6ennjllVfwzDPPtNjX09MT27dvx9q1a3Hs2DEkJCTAzs4OQUFBmDNnTtd8w0REPZjIxM8RiYj6pPz8fIwfPx5LlizB0qVLhS6HiKhPY085EREREZHAGMqJiIiIiATGUE5EREREJDD2lBMRERERCYwj5UREREREAmMoJyIiIiISGEM5EREREZHAGMqJiIiIiATGUE5EREREJDCGciIiIiIigf1/w74JCTIfYdYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB3a_Js1Vdbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = []\n",
        "classes = []\n",
        "\n",
        "for filename in test_docs:\n",
        "  with io.open(filename+'.txt','r') as f:\n",
        "    file = f.read()\n",
        "  for i in range(len(file.split('\\n'))):\n",
        "    if len(file.split('\\n')[i].split('\\t')) == 2:\n",
        "      s = file.split('\\n')[i].split('\\t')[0]\n",
        "      sent.append(s)\n",
        "      classes.append(file.split('\\n')[i].split('\\t')[1])\n",
        "\n",
        "dic = {'Sentence':sent,'Class':classes}\n",
        "df1 = pd.DataFrame(dic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJCqQO2BVnD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = enc.transform(classes)\n",
        "df1 = pd.concat([df1,pd.DataFrame(list(classes))],axis = 1)\n",
        "df1.columns = ['Sentence','Class','Labels']\n",
        "sentences = df1.Sentence.values\n",
        "labels = df1.Labels.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkq4vPmjVu2O",
        "colab_type": "code",
        "outputId": "018f9c09-aed6-4791-fb78-8ffc738acd4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Leave granted\n",
            "Token IDs: tensor([ 101, 2681, 4379,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpVJ3tWrWWPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_labels = []\n",
        "l = len(input_ids)\n",
        "for i in range(l):\n",
        "  t = model(input_ids[i].unsqueeze(0).cuda(), attention_mask=attention_masks[i].unsqueeze(0).cuda(),labels=labels[i].unsqueeze(0).cuda())[1]\n",
        "  preds_labels.append(np.argmax(t.detach().cpu().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOjuSTijWf-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "dic = classification_report(labels,preds_labels, labels=[0,1,2,3,4,5,6], target_names=['Argument', 'Facts', 'Precedent', 'Ratio of the decision','Ruling by Lower Court', 'Ruling by Present Court', 'Statute'], digits=2, output_dict=True, zero_division='warn')\n",
        "df_report = pd.DataFrame(data = dic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFbVavptWsja",
        "colab_type": "code",
        "outputId": "7f1ba9b9-0230-4d27-e97b-153bc3132915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "df_report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Argument</th>\n",
              "      <th>Facts</th>\n",
              "      <th>Precedent</th>\n",
              "      <th>Ratio of the decision</th>\n",
              "      <th>Ruling by Lower Court</th>\n",
              "      <th>Ruling by Present Court</th>\n",
              "      <th>Statute</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.594080</td>\n",
              "      <td>0.684411</td>\n",
              "      <td>0.505051</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.622222</td>\n",
              "      <td>0.710526</td>\n",
              "      <td>0.579521</td>\n",
              "      <td>0.595899</td>\n",
              "      <td>0.593261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.505952</td>\n",
              "      <td>0.709596</td>\n",
              "      <td>0.443350</td>\n",
              "      <td>0.655738</td>\n",
              "      <td>0.132353</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.632812</td>\n",
              "      <td>0.579521</td>\n",
              "      <td>0.506638</td>\n",
              "      <td>0.579521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.580205</td>\n",
              "      <td>0.646720</td>\n",
              "      <td>0.538117</td>\n",
              "      <td>0.570613</td>\n",
              "      <td>0.195652</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.669421</td>\n",
              "      <td>0.579521</td>\n",
              "      <td>0.533437</td>\n",
              "      <td>0.572503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>168.000000</td>\n",
              "      <td>396.000000</td>\n",
              "      <td>406.000000</td>\n",
              "      <td>610.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>0.579521</td>\n",
              "      <td>1836.000000</td>\n",
              "      <td>1836.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Argument       Facts  ...    macro avg  weighted avg\n",
              "precision    0.680000    0.594080  ...     0.595899      0.593261\n",
              "recall       0.505952    0.709596  ...     0.506638      0.579521\n",
              "f1-score     0.580205    0.646720  ...     0.533437      0.572503\n",
              "support    168.000000  396.000000  ...  1836.000000   1836.000000\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky3k38zIWt6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}