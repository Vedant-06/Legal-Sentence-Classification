{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Project - Hier-BiLstm-CRF_BERT",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sroN270BfxZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9c11a96-e272-4e24-ff99-251a7fe6d9be"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCypjptaglHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4123ee25-94ad-4a6f-f33c-a9a817f1a1eb"
      },
      "source": [
        "%cd /content/drive/My Drive/PROJECT - NLP/semantic-segmentation/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PROJECT - NLP/semantic-segmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjZ-R54rgngo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9158f5e4-a491-4a5f-acd1-73763c98bf02"
      },
      "source": [
        "!python run.py --pretrained True --data_path ./data/pretrained-embeddings_BERT/ --save_path ./saved/ --emb_dim 768 --cat_path ./categories.txt\n",
        "#Please Avoid the Last Fold It was mistake in a Code."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing data ... Done\n",
            "Vocabulary size: 2\n",
            "#Tags: 10\n",
            "\n",
            "Cross-validation\n",
            "\n",
            "\n",
            "Initializing model ... Done\n",
            "\n",
            "Evaluating on fold 0 ...\n",
            "  EPOCH     Tr_LOSS   Tr_F1    Val_LOSS  Val_F1\n",
            "-----------------------------------------------------------\n",
            "     10    5072.205   0.138    2489.932   0.145\n",
            "     20    3494.506   0.422    1848.327   0.380\n",
            "     30    2603.373   0.560    1615.400   0.418\n",
            "     40    2333.273   0.553    1593.443   0.411\n",
            "     50    1674.665   0.667    1434.821   0.461\n",
            "     60    1390.485   0.777    1348.594   0.454\n",
            "     70    1289.337   0.750    1333.001   0.489\n",
            "     80    1011.270   0.798    1389.495   0.483\n",
            "     90     866.687   0.864    1485.581   0.458\n",
            "    100     747.796   0.901    1497.142   0.479\n",
            "    110    3893.763   0.365    2758.568   0.346\n",
            "    120    1534.604   0.643    1152.960   0.464\n",
            "    130    1073.186   0.780    1130.675   0.498\n",
            "    140     922.869   0.846    1168.176   0.507\n",
            "    150     786.096   0.874    1235.228   0.477\n",
            "    160     709.343   0.903    1228.378   0.505\n",
            "    170     676.248   0.898    1348.490   0.481\n",
            "    180     570.248   0.920    1328.842   0.523\n",
            "    190     526.074   0.928    1332.423   0.545\n",
            "    200     469.194   0.940    1560.032   0.493\n",
            "    210     449.739   0.941    1539.088   0.503\n",
            "    220     415.978   0.944    1536.595   0.510\n",
            "    230     362.418   0.952    1610.893   0.521\n",
            "    240     336.447   0.957    1598.128   0.558\n",
            "    250     304.912   0.957    1860.614   0.485\n",
            "    260     269.287   0.966    1781.695   0.511\n",
            "    270     246.864   0.972    1830.136   0.501\n",
            "    280     208.481   0.970    1970.334   0.509\n",
            "    290     190.046   0.979    2057.836   0.526\n",
            "    300     183.107   0.973    2099.959   0.522\n",
            "Dumping model and data ... Done\n",
            "Time taken: 988 secs\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                  Facts      0.738     0.745     0.742       487\n",
            "               Argument      0.564     0.454     0.503       185\n",
            "  Ratio of the decision      0.584     0.679     0.628       658\n",
            "                Statute      0.645     0.840     0.730       119\n",
            "              Precedent      0.567     0.431     0.490       246\n",
            "Ruling by Present Court      0.650     0.542     0.591        48\n",
            "  Ruling by Lower Court      0.567     0.227     0.324        75\n",
            "\n",
            "               accuracy                          0.629      1818\n",
            "              macro avg      0.616     0.560     0.572      1818\n",
            "           weighted avg      0.626     0.629     0.620      1818\n",
            "\n",
            "\n",
            "Initializing model ... Done\n",
            "\n",
            "Evaluating on fold 1 ...\n",
            "  EPOCH     Tr_LOSS   Tr_F1    Val_LOSS  Val_F1\n",
            "-----------------------------------------------------------\n",
            "     10    5619.998   0.169    2113.927   0.142\n",
            "     20    3904.293   0.349    1548.799   0.362\n",
            "     30    2830.859   0.514    1273.918   0.468\n",
            "     40    2159.919   0.618    1175.267   0.532\n",
            "     50    1804.152   0.710    1093.751   0.503\n",
            "     60    1452.054   0.777    1018.341   0.544\n",
            "     70    1223.034   0.792    1052.046   0.536\n",
            "     80    1341.580   0.803    1278.926   0.449\n",
            "     90    1018.171   0.838    1107.918   0.541\n",
            "    100     852.538   0.876    1131.723   0.542\n",
            "    110     762.034   0.891    1142.726   0.552\n",
            "    120     677.890   0.912    1172.883   0.567\n",
            "    130    1524.732   0.630    1150.702   0.464\n",
            "    140     952.537   0.827    1013.181   0.544\n",
            "    150     721.536   0.905    1022.190   0.576\n",
            "    160     649.250   0.907    1169.985   0.554\n",
            "    170     582.588   0.917    1089.976   0.576\n",
            "    180     532.803   0.934    1275.834   0.554\n",
            "    190     482.476   0.932    1238.943   0.538\n",
            "    200     449.386   0.938    1299.344   0.569\n",
            "    210     408.734   0.949    1320.118   0.526\n",
            "    220     393.736   0.950    1247.116   0.547\n",
            "    230     333.825   0.957    1372.757   0.538\n",
            "    240     924.163   0.814    1423.637   0.444\n",
            "    250     671.748   0.890    1247.413   0.497\n",
            "    260     507.340   0.938    1160.507   0.514\n",
            "    270     439.467   0.941    1329.548   0.543\n",
            "    280     369.390   0.949    1275.688   0.502\n",
            "    290     317.365   0.962    1365.781   0.552\n",
            "    300     301.637   0.961    1389.412   0.544\n",
            "Dumping model and data ... Done\n",
            "Time taken: 966 secs\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                  Facts      0.824     0.742     0.781       480\n",
            "               Argument      0.800     0.479     0.599       117\n",
            "  Ratio of the decision      0.564     0.803     0.663       477\n",
            "                Statute      0.824     0.765     0.794        98\n",
            "              Precedent      0.697     0.498     0.581       259\n",
            "Ruling by Present Court      0.800     0.514     0.626        70\n",
            "  Ruling by Lower Court      0.118     0.111     0.114        18\n",
            "\n",
            "               accuracy                          0.683      1519\n",
            "              macro avg      0.661     0.559     0.594      1519\n",
            "           weighted avg      0.709     0.683     0.681      1519\n",
            "\n",
            "\n",
            "Initializing model ... Done\n",
            "\n",
            "Evaluating on fold 2 ...\n",
            "  EPOCH     Tr_LOSS   Tr_F1    Val_LOSS  Val_F1\n",
            "-----------------------------------------------------------\n",
            "     10    5338.719   0.125    2913.238   0.102\n",
            "     20    3839.254   0.328    2192.772   0.329\n",
            "     30    2853.325   0.491    1838.893   0.444\n",
            "     40    2159.375   0.599    1795.030   0.411\n",
            "     50    1769.184   0.660    1630.509   0.445\n",
            "     60    1469.532   0.689    1438.436   0.480\n",
            "     70    1260.685   0.764    1437.376   0.481\n",
            "     80    1079.841   0.813    1381.976   0.530\n",
            "     90    1138.863   0.745    1609.593   0.456\n",
            "    100     913.632   0.853    1606.630   0.480\n",
            "    110     838.659   0.871    1583.739   0.480\n",
            "    120     796.314   0.868    1599.822   0.505\n",
            "    130     679.447   0.904    1602.882   0.491\n",
            "    140     615.786   0.919    1728.265   0.494\n",
            "    150     638.031   0.906    1940.864   0.460\n",
            "    160     523.503   0.931    1846.144   0.499\n",
            "    170     558.176   0.900    1793.676   0.528\n",
            "    180    2994.839   0.531    1875.294   0.369\n",
            "    190    1130.599   0.741    1276.880   0.448\n",
            "    200     887.024   0.844    1313.143   0.490\n",
            "    210     772.138   0.871    1368.125   0.519\n",
            "    220     657.686   0.897    1498.895   0.543\n",
            "    230     607.842   0.911    1568.474   0.519\n",
            "    240     547.488   0.919    1687.484   0.513\n",
            "    250     480.043   0.928    1804.417   0.497\n",
            "    260     439.851   0.940    1826.561   0.508\n",
            "    270     403.329   0.942    1959.703   0.492\n",
            "    280     354.624   0.956    1964.276   0.524\n",
            "    290     346.227   0.956    2135.091   0.491\n",
            "    300     289.615   0.964    2292.733   0.492\n",
            "Dumping model and data ... Done\n",
            "Time taken: 884 secs\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                  Facts      0.771     0.798     0.784       544\n",
            "               Argument      0.479     0.347     0.402       202\n",
            "  Ratio of the decision      0.712     0.638     0.673       949\n",
            "                Statute      0.762     0.547     0.637       117\n",
            "              Precedent      0.357     0.780     0.490       186\n",
            "Ruling by Present Court      0.794     0.643     0.711        42\n",
            "  Ruling by Lower Court      0.238     0.118     0.157        85\n",
            "\n",
            "               accuracy                          0.638      2125\n",
            "              macro avg      0.588     0.553     0.551      2125\n",
            "           weighted avg      0.659     0.638     0.638      2125\n",
            "\n",
            "\n",
            "Initializing model ... Done\n",
            "\n",
            "Evaluating on fold 3 ...\n",
            "  EPOCH     Tr_LOSS   Tr_F1    Val_LOSS  Val_F1\n",
            "-----------------------------------------------------------\n",
            "     10    5038.337   0.158    3018.964   0.122\n",
            "     20    3675.065   0.329    2260.488   0.315\n",
            "     30    2671.888   0.510    1619.344   0.529\n",
            "     40    2055.025   0.620    1512.991   0.529\n",
            "     50    1648.058   0.682    1542.841   0.519\n",
            "     60    1468.182   0.756    1354.213   0.559\n",
            "     70    1198.828   0.791    1300.545   0.571\n",
            "     80    1090.189   0.810    1375.574   0.570\n",
            "     90     951.468   0.841    1266.371   0.599\n",
            "    100     850.074   0.861    1521.719   0.522\n",
            "    110     816.852   0.841    1343.011   0.576\n",
            "    120     687.525   0.897    1521.947   0.549\n",
            "    130     712.802   0.882    1573.901   0.534\n",
            "    140     583.562   0.918    1669.364   0.552\n",
            "    150     526.103   0.921    1583.081   0.580\n",
            "    160     625.879   0.892    1987.492   0.500\n",
            "    170     476.535   0.940    1731.401   0.540\n",
            "    180     403.904   0.950    1880.349   0.575\n",
            "    190     365.401   0.952    1949.763   0.558\n",
            "    200     350.783   0.953    1864.336   0.575\n",
            "    210     317.511   0.960    1746.583   0.593\n",
            "    220     297.734   0.966    1908.503   0.588\n",
            "    230    1844.092   0.581    1754.201   0.429\n",
            "    240     900.202   0.825    1288.926   0.558\n",
            "    250     684.155   0.871    1316.854   0.590\n",
            "    260     542.686   0.906    1398.241   0.578\n",
            "    270     486.299   0.930    1450.429   0.598\n",
            "    280     435.401   0.937    1519.196   0.600\n",
            "    290     389.473   0.935    1474.635   0.610\n",
            "    300     344.398   0.950    1598.991   0.596\n",
            "Dumping model and data ... Done\n",
            "Time taken: 981 secs\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                  Facts      0.668     0.905     0.769       294\n",
            "               Argument      0.691     0.644     0.667       188\n",
            "  Ratio of the decision      0.630     0.762     0.690       736\n",
            "                Statute      0.790     0.721     0.754       251\n",
            "              Precedent      0.817     0.507     0.626       475\n",
            "Ruling by Present Court      0.731     0.884     0.800        43\n",
            "  Ruling by Lower Court      0.214     0.075     0.111        80\n",
            "\n",
            "               accuracy                          0.684      2067\n",
            "              macro avg      0.649     0.643     0.631      2067\n",
            "           weighted avg      0.690     0.684     0.672      2067\n",
            "\n",
            "\n",
            "Initializing model ... Done\n",
            "\n",
            "Evaluating on fold 4 ...\n",
            "  EPOCH     Tr_LOSS   Tr_F1    Val_LOSS  Val_F1\n",
            "-----------------------------------------------------------\n",
            "     10         nan   0.000         nan   0.000\n",
            "     20         nan   0.000         nan   0.000\n",
            "     30         nan   0.000         nan   0.000\n",
            "     40         nan   0.000         nan   0.000\n",
            "     50         nan   0.000         nan   0.000\n",
            "     60         nan   0.000         nan   0.000\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 64, in <module>\n",
            "    main()\n",
            "  File \"run.py\", line 51, in main\n",
            "    learn(model, x, y, tag2idx, f, args)\n",
            "  File \"/content/drive/My Drive/PROJECT - NLP/semantic-segmentation/train.py\", line 155, in learn\n",
            "    train_loss, train_idx, train_gold, train_pred = train_step(model, opt, train_x, train_y, args.batch_size)\n",
            "  File \"/content/drive/My Drive/PROJECT - NLP/semantic-segmentation/train.py\", line 57, in train_step\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 198, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 100, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvXYcnpWHvdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "7ba6ca3e-bd0d-47c5-8baf-71b49ef8b94e"
      },
      "source": [
        "!python run.py --pretrained True --data_path ./data/pretrained-embeddings_BERT/ --save_path ./saved/ --emb_dim 768 --cat_path ./categories.txt --val_fold 4 --num_folds 5"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing data ... Done\n",
            "Vocabulary size: 2\n",
            "#Tags: 10\n",
            "\n",
            "Initializing model ... Done\n",
            "\n",
            "Evaluating on fold 4 ...\n",
            "  EPOCH     Tr_LOSS   Tr_F1    Val_LOSS  Val_F1\n",
            "-----------------------------------------------------------\n",
            "     10    5120.888   0.213    2386.093   0.242\n",
            "     20    3388.748   0.463    1765.923   0.446\n",
            "     30    2595.157   0.522    1530.881   0.518\n",
            "     40    2003.364   0.636    1386.403   0.499\n",
            "     50    1705.388   0.660    1312.258   0.521\n",
            "     60    1385.503   0.720    1391.718   0.511\n",
            "     70    1081.045   0.806    1292.148   0.544\n",
            "     80    1416.663   0.638    1294.695   0.501\n",
            "     90     925.582   0.842    1205.137   0.547\n",
            "    100     756.175   0.894    1295.554   0.576\n",
            "    110     608.430   0.917    1368.199   0.587\n",
            "    120    3208.001   0.472    2325.953   0.318\n",
            "    130    1324.716   0.768    1170.135   0.543\n",
            "    140     932.755   0.833    1225.410   0.579\n",
            "    150     721.824   0.894    1330.344   0.554\n",
            "    160     607.968   0.914    1361.356   0.572\n",
            "    170     523.826   0.928    1504.601   0.540\n",
            "    180     432.518   0.945    1590.537   0.587\n",
            "    190     396.299   0.943    1629.489   0.561\n",
            "    200     348.396   0.951    1683.191   0.556\n",
            "    210     250.941   0.972    1787.738   0.565\n",
            "    220     216.195   0.979    1739.802   0.564\n",
            "    230     200.367   0.979    2231.925   0.547\n",
            "    240     215.605   0.972    1963.304   0.572\n",
            "    250     141.337   0.987    2028.244   0.591\n",
            "    260     115.647   0.989    2431.459   0.553\n",
            "    270     100.953   0.993    2280.823   0.545\n",
            "    280      79.591   0.995    2420.975   0.557\n",
            "    290      70.335   0.995    2367.758   0.590\n",
            "    300      68.600   0.994    2372.486   0.572\n",
            "Dumping model and data ... Done\n",
            "Time taken: 946 secs\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                  Facts      0.818     0.531     0.644       414\n",
            "               Argument      0.431     0.553     0.484       152\n",
            "  Ratio of the decision      0.659     0.823     0.732       804\n",
            "                Statute      0.681     0.525     0.593        61\n",
            "              Precedent      0.725     0.619     0.668       302\n",
            "Ruling by Present Court      0.952     0.678     0.792        59\n",
            "  Ruling by Lower Court      0.412     0.246     0.308        57\n",
            "\n",
            "               accuracy                          0.670      1849\n",
            "              macro avg      0.668     0.568     0.603      1849\n",
            "           weighted avg      0.689     0.670     0.666      1849\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAnMeJIkbg0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}